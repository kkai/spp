{
  "spp_number": "SPP 2481",
  "spp_title": "Blicke verstehen",
  "spp_url": "https://gepris.dfg.de/gepris/projekt/540857726",
  "projects_count": 12,
  "projects": [
    {
      "project_id": "563097140",
      "url": "https://gepris.dfg.de/gepris/projekt/563097140",
      "title": "AEyeCoL: Erweitertes Verständnis des Blickverhaltens bei kollaborativem Lernen",
      "investigators": "Dr. Babette  Bühler;Dr. TIm  Fütterer;Professorin Dr. Enkelejda  Kasneci;Professor Dr. Ulrich  Trautwein",
      "subject_area": "Bild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable ComputingAllgemeines und fachbezogenes Lehren und Lernen",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563097140",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Kollaboratives Lernen (CL) ist ein zentraler 21st Century Skill, der für die Förderung von kritischem Denken, Problemlösung und lebenslangem Lernen bekannt ist. Während die Auswirkungen von CL auf die Lernergebnisse umfassend erforscht wurden, ist über die nonverbalen Mechanismen, die einer erfolgreichen Zusammenarbeit zugrunde liegen, wesentlich weniger bekannt. Dieses Projekt zielt darauf ab, unser Verständnis der Blickdynamik in Gruppenarbeit mit Hilfe mobilen Eye-Trackings und maschinellen Lernens (ML) zu verbessern. Durch die Analyse von Blickinteraktionen, wie z.B. gemeinsame visuelle Aufmerksamkeit (JVA), JVA-Initialisierung und Blickkontakt, wollen wir die sozialen und kognitiven Prozesse aufdecken, die eine effektive Zusammenarbeit fördern. Das vorgeschlagene Projekt hat fünf Hauptziele: (O1) Erstellung eines umfassenden Sets von Blickindikatoren auf Gruppenebene, die für CL relevant sind. (O2) Entwicklung einer automatisierten Blickanalyse-Pipeline unter Verwendung von Computer-Vision-Methoden, die die manuelle Annotation von Bereichen von Interesse ersetzt, um Blickindikatoren zu extrahieren, und deren Veröffentlichung als Open-Source-Ressource. (O3) Veröffentlichung eines anonymisierten, großen Eye-Tracking-Datensatzes für die zukünftige Forschung. (O4) Vorhersage der Teamdynamik, wie z.B. das Aufkommen von Führungsrolle und Turn-Taking, mit ML-Modellen auf der Grundlage von Blickindikatoren. (O5) Übertragung und Anpassung der Methoden auf reale Bildungssituationen mit Kindern im Schulalter, um die Wechselwirkung zwischen Blickdynamik, Gruppenprozessen und Lernergebnissen zu beleuchten. Durch zwei aufeinander aufbauende CL-Studien, von denen die erste mit Studierenden und die zweite mit Grundschulkindern durchgeführt wird, werden wir kritische Forschungslücken schließen, darunter das Fehlen umfassender Blickindikatoren, die über JVA hinausgehen, der Mangel an Instrumenten für skalierbare Analysen und der begrenzte Fokus auf naturalistische und Multi-User-Settings in der Forschung. Durch die Untersuchung der Frage, wie das Blickverhalten die Teamdynamik widerspiegelt und wie es mit der Instruktionsqualität und den Lernerfolg zusammenhängt, wird dieses Projekt neue Einblicke in die Prozesse bieten, die effektivem CL zugrunde liegen. Die Ergebnisse werden zur Veröffentlichung eines Eye-Tracking Datensatzes, eines Open-Source-Frameworks für die Blickanalyse und Richtlinien für die Verbesserung von CL sowohl im Hochschul- als auch im Schulkontext führen. Unser interdisziplinärer Ansatz, steht im Einklang mit UGaze, indem er das Verständnis der Blickdynamik in CL fördert, durch die Entwicklung skalierbarer Werkzeuge und eines Datensatzes eine Brücke zwischen Gaze-Sharing und Gaze-Based Interaction schlägt, die gemeinschaftlich betriebene Forschung fördert und Anwendungen in verschiedenen Bildungs- und Multi-User-Kontexten ermöglicht.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehenMitverantwortlichProfessor Dr. Peter  Gerjets"
    },
    {
      "project_id": "562910865",
      "url": "https://gepris.dfg.de/gepris/projekt/562910865",
      "title": "Blicksignalisierung bei verschieden skalierten interaktiven und kollaborativen Handlungen (GazeACT)",
      "investigators": "Professor Dr. Rouwen  Cañal Bruland;Professorin Dr. Katja  Fiehler",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 562910865",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Die Erforschung von Augenbewegungen zur Untersuchung von perzeptuellen und kognitiven Prozessen wurde primär in isolierten Szenarien (mit nur einem Beobachter) untersucht, selbst wenn das Ziel verfolgt wurde, soziale Interaktionen und/oder Kollaborationen zu untersuchen. Es gibt zwar einige Hinweise darauf, dass das Blickverhalten in verschieden skalierten interaktiven und kollaborativen Handlungen hochgradig informativ für das Erkennen von Absichten anderer sein kann, unser allgemeines Verständnis der Blicksignalisierung in solchen Szenarien ist aber sehr begrenzt. Ziel dieses Tandem-Forschungsvorhabens ist es daher, die Funktion der Blicksignalisierung bei der Steuerung von Hand- und Ganzkörperbewegungen in dynamischen, interaktiven und kollaborativen Aufgaben in Echtzeit zu untersuchen und dabei die Blicke von zwei Individuen (d.h. zwei Interagierenden/zwei Kollaborateuren) zu messen. Interaktive Aufgaben beziehen sich auf Szenarien, bei denen zwei Individuen interagieren, während jedes Individuum seine eigenen Ziele verfolgt (z.B. das Greifen und Übergeben eines Objekts oder das Vorbeigehen an einem anderen Individuum ohne Kollision). Im Gegensatz dazu beziehen sich kollaborative Aufgaben auf Szenarien, bei denen zwei Individuen eine Aufgabe gemeinsam ausführen, um ein gemeinsames Ziel zu erreichen (z.B. ein Objekt gemeinsam greifen und anheben, um es in einen Rahmen einzupassen, oder einen Tisch gemeinsam tragen, um diesen gezielt durch den Raum zu manövrieren). Die Untersuchung dieser Aufgaben wird es uns ermöglichen, (i) Blickmuster bei interaktiven und kollaborativen Handlungen zu identifizieren, zu charakterisieren und zu vergleichen und insbesondere zu verstehen, (ii) wie sich die Blicksignalisierung und ihre Interpretation über den zeitlichen Verlauf von Handlungen verändert, und (iii) wie sie von Faktoren der anderen Person (z.B. Informationswert des Blicks des anderen) und der gemeinsamen Aufgabe (z.B. Schwierigkeit der Aufgabe) beeinflusst wird. Mit diesem Tandem-Ansatz verschieden skalierter Handlungen zielt dieses Projekt darauf ab, einen bedeutenden Beitrag zu zwei Entwicklungsbereichen von UGaze zu leisten, nämlich (I) Gaze Expression und (II) Gaze Sharing, und zwar über eine breite Palette von alltäglichen, sozialen interaktiven und kollaborativen Aufgaben.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563097773",
      "url": "https://gepris.dfg.de/gepris/projekt/563097773",
      "title": "Blickverstehen bei zufälligen Begegnungen",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563097773",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Wenn Menschen einander in öffentlichen Räumen begegnen, vermeiden sie ohne Aufwand Zusammenstöße und handeln die Nutzung des Raums implizit miteinander aus. Wir untersuchen wie gegenseitiges Blickverstehen zu solchen zufälligen, kurzzeitigen Interaktionen beiträgt. Als Mittelweg zwischen Realismus und experimenteller Kontrolle verwenden wir für die meisten Experimente virtuelle Realität (VR). In einem ersten Schritt messen wir präzise Augen-, Kopf- und Körperbewegungen von Versuchspersonen, die ihren Blick auf ein peripheres Ziel richten, während sie gehen. Wir übertragen die gemessenen Daten auf virtuelle Menschen (Avatare), deren realistische Darstellung wir in einem separaten Experiment untersuchen und die wir für alle folgenden VR-Experimente einsetzen. In einer ersten Reihe an VR-Experimenten untersuchen wir Begegnungen, in denen Interaktionen zwischen Versuchsperson und Avatar nicht notwendig sind. Konkret begegnen die Versuchspersonen einer Reihe von Avataren in einem Korridor eines virtuellen Gebäudes und wir untersuchen, inwieweit die Blicke der Avatare die Blicke der Versuchspersonen und deren Handlungen beeinflussen. In Varianten des Experiments führen die Versuchspersonen einfache Alltagsaufgaben aus und wir prüfen, wie diese die Blickinteraktionen mit den Avataren beeinflussen. Zur Validierung der VR-Experimente wiederholen wir einen Teil der Experimente in der realen Welt; dabei begegnen die Versuchspersonen anderen Personen, die von der Versuchsleitung bezüglich ihres Blickverhaltens instruiert wurden. Dieser Ansatz nutzt aus, dass die verwendete VR dem Gebäude nachempfunden ist, in welchem das Experiment in der realen Welt durchgeführt wird. In einer zweiten Reihe an Experimenten untersuchen wir Situationen, in denen ein Konflikt um die Raumnutzung unmittelbar bevorsteht. Im Grund-Szenario nähern sich Versuchsperson und Avatar von verschiedenen Seiten einer undurchsichtigen Schiebetür. Sobald die Tür sich öffnet, muss einer der Akteure ausweichen, damit beide weitergehen können. Wir untersuchen wie wechselseitige Blicke verwendet werden, um das Vorgehen in solchen Situationen auszuhandeln, und wie dieses Blickverhalten durch räumliche Beschränkungen oder Umgebungskontext (z.B. wer betritt, wer verlässt einen engeren Raum wie einen Fahrstuhl) beeinflusst wird. Zusammengenommen werden unsere Experimente Einblicke erlauben, wie der Ausdruck des Blicks und gegenseitiges Blickverstehen Menschen dabei helfen, sich sicher und leichtgängig durch öffentliche Räume zu bewegen. Während das aktuelle Projekt sich auf dyadische (Zwei-Personen-) Interaktionen beschränkt, ist der generelle Ansatz leicht auf Szenarien mit vielen Akteuren, z.B. das Durchqueren einer gut gefüllten Bahnhofshalle, erweiterbar.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563020667",
      "url": "https://gepris.dfg.de/gepris/projekt/563020667",
      "title": "CrowdGaze: Ein dualer Ansatz zur Untersuchung von Blickinteraktionen in stationären und sich bewegenden Menschenmengen unter Verwendung von Eye Tracking in realen und virtuellen Umgebungen.",
      "investigators": "Professor Dr. Torsten Wolfgang  Kuhlen;Professorin Dr. Anna  Sieben",
      "subject_area": "Sozialpsychologie und Arbeits- und OrganisationspsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable Computing",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563020667",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "CrowdGaze untersucht, wie Blickinteraktionen die nonverbale Aushandlung von Raum und soziale Koordination in dichten, dynamischen Menschenmengen sowohl in realen als auch in immersiven virtuellen Umgebungen erleichtern. Im Gegensatz zu Herdentieren mit weiten Gesichtsfeldern, die müheloses Gruppenverhalten ermöglichen, sind die nach vorne gerichteten Augen des Menschen für die Kommunikation von Angesicht zu Angesicht optimiert. Sie sind jedoch weniger effektiv in Menschenmengen, insbesondere wenn die Dichte 2–4 Personen pro Quadratmeter überschreitet. Trotz dieser Einschränkungen spielt der Blick eine doppelte Rolle: Er hilft Individuen, Bewegungsintentionen zu interpretieren und Aktionen zu koordinieren, während er gleichzeitig soziale Normen, Rollen und angemessenes Verhalten vermittelt. Unser Projekt untersucht das Blickverhalten in drei alltäglichen Szenarien: (A) Warten in dichten Menschenmengen, (B) Bewegung in unidirektionalen Menschenmengen, und (C) Verhandlung von sozialen Normen in Wartesituationen. In Szenario A vermeiden Personen oft direkten Augenkontakt, um Unbehagen zu reduzieren, während sie dennoch ihre Umgebung im Auge behalten. Szenario B konzentriert sich auf die Bewegungskoordination und erforscht, wie der Blick Änderungen der Gehrichtung anzeigt, Zugehörigkeit innerhalb von Gruppen signalisiert und Führung erleichtert. In Szenario C fungiert der Blick als soziales Signal zur Durchsetzung von Normen – missbilligende Blicke können Überholende abschrecken, während Überholende selbst ihren Blick abwenden können, um Konflikte zu vermeiden. Dieses interdisziplinäre Projekt vereint Expertise aus Sozialpsychologie, Bewegungswissenschaft und Computerwissenschaft/virtuelle Realität. Zunächst werden Blickverhaltensmuster in natürlichen Menschenmengen mittels realer Experimente (REs) mit Eye Tracking identifiziert. Diese Experimente werden anschließend unter kontrollierten Bedingungen in virtueller Realität (VR) repliziert, um Unterschiede und Ähnlichkeiten im Blickverhalten zwischen beiden Kontexten zu untersuchen. Basierend auf diesen Erkenntnissen entwickeln wir Algorithmen zur Verbesserung des Designs computergesteuerter virtueller Agenten. Diese sollen als virtuelle Fußgänger eingebettet werden und realistischere Simulationen menschlicher Interaktionen in bevölkerten Umgebungen ermöglichen. Die Ergebnisse tragen dazu bei, die Sicherheit in Menschenmengen zu erhöhen, z.B. durch ein verbessertes Design öffentlicher Räume, und Methoden zur Untersuchung des Blickverhaltens in dynamischen Umgebungen voranzutreiben. Folglich leistet CrowdGaze einen bedeutenden Beitrag zum Verständnis menschlichen Verhaltens in realen und virtuellen Menschenmengen und stellt eine wesentliche Ergänzung zur SPP UGAZE-Initiative dar.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehenInternationaler BezugFrankreichKooperationspartnerinDr. Anne-Hélène  Olivier"
    },
    {
      "project_id": "562993814",
      "url": "https://gepris.dfg.de/gepris/projekt/562993814",
      "title": "Dekodierung der Semantik basaler Blickmuster: Auf dem Weg zu einer theoretisch unvoreingenommenen Extraktion von Bedeutungen sowie deren Abhängigkeit von situationalen Anforderungen",
      "investigators": "Professorin Dr. Anne  Böckler-Raettig;Professor Dr. Lynn  Huestegge",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 562993814",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Viele nonverbale Kommunikationssignale während sozialer Interaktionen haben ihren Ursprung in der Mimik und insbesondere in Blickmustern. Überraschenderweise ist systematische Forschung darüber, wie grundlegende Blickmuster interpretiert werden, immer noch selten. Neben einem geplanten systematischen Literatur-Review zum Thema untersuchen wir hier empirisch, wie grundlegende Blickmuster verstanden werden, basierend auf einer kürzlich veröffentlichten Pilotstudie unserer Gruppe. Wir verwenden einen neuartigen zweistufigen qualitativ-quantitativen experimentellen Ansatz, um die Semantik von Blickmustern (und deren kontextuelle Modulationen) zu entschlüsseln. Wir untersuchen die Auswirkungen verschiedener Blickmuster eines Avatars auf die Blickwahrnehmung, indem wir die Teilnehmer Videos von Personen ansehen lassen, die verschiedenen Typen von Erzählungen (zur Variation situationaler Anforderungen) zuhören. Der Blick der Zuhörer wird in Bezug auf die Blickrichtung (direkt/oben/unten/seitlich) und die Blickwechsel-/Blinzelfrequenz manipuliert. In einer qualitativ-explorativen Stufe beschreiben Teilnehmer frei, welche Zustände/Eigenschaften sie den verschiedenen Blickmustern zuschreiben, um etwaige theoretische Biases früherer Studien auszuschließen. Anschließend konstruieren wir Bewertungsskalen für die nachfolgende quantitativ-konfirmatorische Stufe. Die Augenbewegungen der Teilnehmer werden gemessen, um festzustellen, wie diese zum Verständnis der Blicke beitragen. Wir wollen die systematischen Bedeutungen aufdecken, die dem Blickverhalten in verschiedenen Situationen zugeschrieben werden. Das Projekt überträgt diesen Ansatz dann auf reale Situationen, in denen Gesprächspartner Blickmuster zeigen (anstelle von Videos), um gegenseitige Blickinteraktion zu analysieren. Wir untersuchen auch, was natürliche Blickmuster auszeichnet, indem wir natürliche Blickbewegungen in vergleichbaren Situationen als Modell für die Avatarprogrammierung aufzeichnen. Schließlich werden wir auch das Verständnis des Blicks in Verhandlungssituationen analysieren. Dieses Projekt ist ein wichtiger Schritt in Richtung eines systematischen Verständnisses der Bedeutung von Blicken.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehenMitverantwortlichDr. Benedict C. O. F.  Fehringer"
    },
    {
      "project_id": "563076576",
      "url": "https://gepris.dfg.de/gepris/projekt/563076576",
      "title": "Einfluss sozialer Ängstlichkeit auf Blickwahrnehmung und -dynamik in interaktiven Umgebungen",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieBiologische Psychologie und Kognitive Neurowissenschaften",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563076576",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Blicke sind von essenzieller Bedeutung in sozialen Situationen. Zum einen wird darüber die Aufnahme von Informationen reguliert, gleichzeitig jedoch auch der eigene Aufmerksamkeitsfokus an andere Personen signalisiert. Diese doppelte Rolle erleichtert die Koordination und Strukturierung von zwischenmenschlichen Interaktionen. Menschen mit sozialen Angststörungen berichten häufig von einer intensiven Angst, beobachtet und bewertet zu werden. Dennoch sind die Ergebnisse bisheriger Eye-Tracking-Studien inkonsistent und konnten keine substanziellen Anomalien im Blickverhalten sozial ängstlicher Personen nachweisen. Diese Diskrepanz könnte darauf zurückzuführen sein, dass sich frühere Studien oft auf relativ artifizielle Laborsettings stützten, eher globale Analysen des Blickverhaltens auf Basis hoch aggregierter Maße vornahmen und die Komplexität dynamischer Interaktionen nicht ausreichend berücksichtigten. Eine Steigerung der ökologischen Validität experimenteller Designs und die Nutzung von Analysen zeitlicher Dynamiken könnten ein umfassenderes Verständnis dafür liefern, wie soziale Angst das Blickverhalten beeinflusst. Solche Erkenntnisse könnten zudem verdeutlichen, wie spezifische Blickmuster zur Aufrechterhaltung klinischer Symptome beitragen, indem sie negative Reaktionen bei Interaktionspartnern auslösen. Das vorliegende Forschungsprojekt adressiert diese Fragen, indem Verhaltensäußerungen und physiologische Daten während sozialer Interaktionen untersucht werden. Dafür sollen innovative Methoden in realen Interaktionssituationen sowie in virtuellen Szenarien mit KI-gesteuerten Agenten genutzt werden. Im Rahmen von drei umfassenden Studien soll untersucht werden, wie soziale Angst und der emotionale Kontext die Dynamik des Blickverhaltens und die physiologische Erregung beeinflussen. Mithilfe von Cross-Recurrence-Quantifizierungsanalysen sollen Muster in der Interaktion zwischen Individuen identifiziert werden. Zudem wird durch die gezielte Manipulation des Blickverhaltens in virtueller Realität untersucht, wie sich solche Veränderungen kausal auf die Wahrnehmung der Gesprächsqualität und die Bewertung des Interaktionspartners auswirken. Diese Forschung verspricht tiefergehende Einblicke in die komplexen Zusammenhänge zwischen sozialer Angst, Blickverhalten sowie physiologischen und subjektiven Korrelaten. Darüber hinaus bietet die Entwicklung einer innovativen Virtual-Reality-Plattform zur Untersuchung komplexer sozialer Phänomene unter kontrollierten Bedingungen einen wegweisenden Ansatz für zukünftige Studien in diesem Bereich. Neben der Erweiterung unseres Verständnisses über die regulatorische Funktion von Blickkontakt in natürlichen sozialen Interaktionen besitzen diese Erkenntnisse auch klinische Relevanz und könnten mittelfristig zur Entwicklung gezielter therapeutischer Strategien für Menschen mit sozialen Angststörungen beitragen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563079426",
      "url": "https://gepris.dfg.de/gepris/projekt/563079426",
      "title": "Gleichzeitiger Blickkontakt und Blinzelsynchronisation als Prädiktoren für erfolgreiche Kooperation",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563079426",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Das geplante Projekt untersucht die Rolle des gegenseitigen Blickkontakts und der Blinzelsynchronisation bei der Förderung von zwischenmenschlichem Vertrauen, Kooperation und Problemlösungsfähigkeit. Aufbauend auf dem Schwerpunktprogramm „Understanding Gaze (UGaze)“ ist diese Forschung auf das Thema (II) „Gaze Sharing“ ausgerichtet und untersucht, wie die Blickdynamik Verhaltensergebnisse in sozialen und kollaborativen Situationen beeinflusst. Mit Hilfe von dualer mobiler Eye-Tracking-Technologie wollen wir Blickinteraktionen in Echtzeit und ihre Auswirkungen auf Vertrauen und Entscheidungsfindung in einem wirtschaftlichen Vertrauensspiel sowie auf die Problemlösungseffizienz im Hidden-Profile-Paradigma erfassen. In der ersten Studie untersuchen wir die Auswirkungen von gegenseitigem Blickkontakt und Blinzelsynchronisation auf zwischenmenschliches Vertrauen und kooperatives Verhalten während wirtschaftlicher Vertrauensspiele von Angesicht zu Angesicht. Die Forschungsfragen konzentrieren sich auf das Ausmaß, in dem die Blickdynamik die Vertrauensbildung beeinflusst, und auf die Beziehung zwischen Blickkontakt und Blinzelsynchronisation. In der zweiten Studie wird diese Untersuchung auf kooperative Problemlösungsszenarien ausgedehnt und untersucht, wie die gemeinsame Aufmerksamkeit, vermittelt durch Blickkontakt und Blinzelsynchronisation, zur Problemlösungsleistung beiträgt. Außerdem untersuchen wir das Zusammenspiel zwischen geteilten Informationen und Blicksynchronisation und stellen die Hypothese auf, dass eine höhere Synchronisation kollektive kognitive Prozesse fördert. Dieses Projekt schließt wichtige Lücken im Verständnis des Blicks als Werkzeug mit Doppelfunktion - sowohl der Wahrnehmung als auch der sozialen Wahrnehmung - und bietet Einblicke in die Mechanismen der Synchronisation in kooperativen und problemlösenden Kontexten. Durch die Weiterentwicklung von Methoden mit dualem mobilem Eye-Tracking werden unsere Ergebnisse theoretische und praktische Implikationen für die Verbesserung der Zusammenarbeit in pädagogischen, organisatorischen und technologischen Umgebungen bieten.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehenInternationaler BezugItalien, ÖsterreichKooperationspartnerDr. Thomas  Maran"
    },
    {
      "project_id": "563020847",
      "url": "https://gepris.dfg.de/gepris/projekt/563020847",
      "title": "Koordinationsfonds",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable Computing",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563020847",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Die Augen, metaphorisch Fenster zur Seele, sind seit dem letzten Jahrhundert Gegenstand der Blickbewegungsforschung. Im Rahmen dieser Forschung wurden verschiedene für die Wahrnehmung und kognitive Verarbeitung zentrale Blickmaße identifiziert. In der kognitiven Psychologie hat man Faktoren identifiziert, die den Fixationen, Sakkaden oder Pupillenbewegungen zugrunde liegen, und so umfassende Modelle der menschlichen Wahrnehmung und Handlung entwickelt. In der Mensch-Computer-Interaktion hat die Verschmelzung von blickbasierter Interaktion mit maschinellem Lernen den Weg für intuitivere Interaktionen geebnet. Bislang wurden jedoch verschiedene Parameter (z. B. Fixationen, Pupillenbewegungen) in der Regel isoliert untersucht. Zudem wurde primär eine einzelne Person vor einem Bildschirm untersucht. Die Anwendung der Erkenntnisse „in the wild“, also auch in Anwesenheit anderer Menschen, ist daher eine Herausforderung: Da der Blick nicht nur Aufmerksamkeits- und Wahrnehmungs-, sondern auch Signalfunktionen erfüllt, verändert sich das Blickverhalten in der freien Natur durch explizite und implizite Interaktion; der Blickaustausch (joint attention) ist für die Interaktion zentral. Um dies in Videokonferenzen oder Augmented/Virtual Reality (AR/VR) nutzen zu können, ist es wichtig, die Dynamik des Blickaustauschs zu verstehen. Jüngste Fortschritte bei den Rechenkapazitäten und der Miniaturisierung der Hardware ermöglichen nun die Untersuchung mit Hilfe von eye tracking-Brillen, die kaum von üblichen Brillen unterscheidbar sind. Wir haben drei wichtige Entwicklungsbereiche für eine koordinierte Forschung identifiziert: (I) Blickausdruck: Die Bedingungen, die dazu führen, dass wir uns beobachtet fühlen, auch die Art und Weise, wie Blicke interpretiert werden, sind noch zu wenig erforscht. Das Verständnis des beobachtenden Blicks erfordert die Erforschung der Blickverfolgung im Hinblick auf die emotionale Konnotation und ihre soziale Einbettung. (II) Gemeinsame Blicke: Verschiedene Blickinteraktionen, einschließlich des gemeinsamen Betrachtens und des gegenseitigen Blicks, haben Mechanismen und Auswirkungen, die noch unklar sind. Die Analyse dieser Interaktionen ist entscheidend für das Verständnis der Signal- und Wahrnehmungsfunktionen des Blicks. All diese Erkenntnisse müssen im Rahmen von (III) Blick-Interaktion in Multi-User-Szenarien systematisch konsolidiert werden: Auch bei blickbasierten Interaktionsanwendungen dominieren Einzelnutzerszenarien das Feld. In vielen Situationen, wie z.B. bei öffentlichen Displays oder Videokonferenzen, können blickbasierte Schnittstellen jedoch eine schnelle und entfernte Interaktion ermöglichen. Für all dies müssen verschiedene Blickparameter integriert und die Interaktion zwischen den Nutzenden untersucht werden, um die kollektive Dynamik zu erfassen. Die Forschungsbereiche profitieren gegenseitig von Fortschritten und Technologien, die tiefere Einblicke in die Blickinteraktionen mehrerer Nutzer ermöglichen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563076722",
      "url": "https://gepris.dfg.de/gepris/projekt/563076722",
      "title": "Spielende Augen: Die kommunikative Kraft von Blickausdrücken beim Bluffen und Gewinnen verstehen",
      "investigators": "Professorin Dr. Anke  Huckauf;Professor Dr. Enrico  Rukzio",
      "subject_area": "Bild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable ComputingAllgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563076722",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Der weit verbreitete Glaube, dass „die Augen niemals lügen“, legt nahe, dass der Blick eines der so genannten ehrlichen Signale ist, die die wahren Absichten und Gefühle einer Person offenbaren. Menschen legen jedoch großen Wert auf ihre Privatsphäre und versuchen oft, nicht mehr preiszugeben als beabsichtigt. Wir haben jedoch nur ein begrenztes Verständnis davon, welche Blickmaße (z. B. Fixationsrate, Blinzelfrequenz und Pupillenbewegung) solche inneren Zustände ausdrücken und wie andere Personen diese in Interaktionen wahrnehmen. In der bisherigen Forschung werden Blickmaße oft isoliert und in kontrollierten nicht-sozialen Umgebungen untersucht, was ihre Anwendbarkeit auf dynamische soziale Interaktionen einschränkt. Daher werden wir Blickausdrücke und ihre Wahrnehmung in sozialen Situationen untersuchen. Kartenspiele wurden als Versuchsumgebung gewählt, da sie eine kontrollierte und dennoch dynamische Umgebung bieten, in der die Spieler ihren Blick strategisch einsetzen, um andere zu beeinflussen. Spiele bieten die Möglichkeit zur parallelen Untersuchung von authentischen sozialen Interaktionen in realen Umgebungen und simulierten virtuellen Umgebungen.  Virtuelle Umgebungen haben den Vorteil, dass sie eine sehr präzise Manipulation von Blicken in einem virtuellen Avatar erlauben, was in realen Umgebungen nicht möglich ist. Dies bietet ein einzigartiges Testfeld für die Erforschung des Blickausdrucks in einer sehr kontrollierten Weise. Darüber hinaus ermöglicht die virtuelle Umgebung die Untersuchung der Wahrnehmung der Blickausdrücke der virtuellen Avatare durch menschliche Spieler. Das Projektziel ist es daher, im Rahmen von Ziel 1 die Blickausdrücke von Spielern beim Bluffen, beim Nicht-Bluffen und bei geringer oder hoher Gewinnzuversicht beim Kartenspielen zu messen und zu quantifizieren. Darauf aufbauend konzentrieren wir uns in Ziel 2 darauf festzustellen, ob diese Blickausdrücke als sinnvolle kommunikative Signale erzeugt und interpretiert werden. Zudem werden wir untersuchen, wie der Blickausdruck der Spieler in strategischen Momenten wie Bluffen und Zuversicht den Spielausgang und die Reaktionen der Spieler vorhersagen kann und wie der Blickausdruck eines Avatars das Verhalten der Spieler manipulieren kann (Ziel 3). Das Projekt wird unser Verständnis des menschlichen Blicks in realen und virtuellen Umgebungen hinsichtlich Blickausdruck, Blickwahrnehmung und sozialer Interaktion im Kontext der betrachteten kognitiv-affektive Zustände grundsätzlich erweitern. Dieses Wissen ist auch für die Entwicklung von Technologien relevant, die in der Lage sind, menschliche Emotionen und Absichten in digitalen Umgebungen zu interpretieren. Dies kann zur Entwicklung von anspruchsvolleren virtuellen Agenten beitragen, die sich an die mentalen Zustände der Nutzer anpassen und bspw. digitale Kommunikation, Zusammenarbeit und therapeutische Interventionen verbessern.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563096772",
      "url": "https://gepris.dfg.de/gepris/projekt/563096772",
      "title": "Vertrauliche Interaktionen mittels Augenkontakt (VIA)",
      "investigators": "Professorin Dr. Martine  Grice;Dr. Mathis  Jording",
      "subject_area": "Sozialpsychologie und Arbeits- und OrganisationspsychologieAllgemeine und Vergleichende Sprachwissenschaft, Experimentelle Linguistik, Typologie, Außereuropäische Sprachen",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563096772",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "In einer Menschenmenge möchten Sie die Aufmerksamkeit Ihres Gegenübers diskret auf ein Objekt von Interesse lenken. Sprechen oder zeigen wäre zu auffällig; Sie können jedoch versuchen, Ihren Partner mit Ihren Augen zu dem Objekt zu führen und mit diesem gemeinsame Aufmerksamkeit (sog. Joint Attention) herzustellen. In einer Umgebung mit vielen verschiedenen Objekten kann dies jedoch zu Missverständnissen führen. Mit diesem Projekt wollen wir untersuchen, wie Joint Attention herstellen und dabei durch den Austausch von Blicksignalen und leisen Rückmeldungen wie „mmhm“ Missverständnisse vermeiden oder ausräumen können. Die verwendeten Strategien können es dabei außenstehende Beobachterinnen erschweren, der Interaktion zu folgen. Wir untersuchen daher, inwieweit der Austausch mittels Joint Attention exklusiv ist, d.h. Außenstehende ausschließt und durch welche Mechanismen diese Exklusivität zustande kommt. Wir unterscheiden dabei zwischen Situationen, in denen Teilnehmer ihren Aufmerksamkeitsfokus und Austausch nicht absichtlich verbergen und Situationen, in denen sie versuchen, geheim zu kommunizieren. Wir zeichnen Augenbewegungen und nicht-sprachliche Äußerungen (Vokalisation) in einer Interaktion zwischen drei Personen mit mobilen Eye-Tracking-Brillen und synchronisierten, qualitativ hochwertigen Audio- und Videorekordern auf. Die Teilnehmer sitzen gemeinsam an einem Tisch, auf dem verschiedene Objekte platziert sind. Eine Teilnehmerin („Sender:in“) muss einem anderen Teilnehmer („Empfänger:in“) die Position bestimmter Zielobjekte mitteilen, und darf Blicke und Stimme, nur Blicke oder nur ihre Stimme verwenden. Die dritte Teilnehmerin ('Beobachter:in') beobachtet die Interaktion und versucht, die Zielobjekte zu erraten. Wir untersuchen, ob Sender:in und Empfänger:in die Vertraulichkeit des Austauschs mittels Joint Attention absichtlich erhöhen und die Beobachter:in daran hindern können, der Interaktion zu folgen. Diese Studie beleuchtet die Rolle und das Potenzial von Joint Attention im Alltag von Erwachsenen. Darüber hinaus werden die Ergebnisse Aufschluss darüber geben, wie Blicksignale mit anderen nonverbalen Modalitäten verbunden werden und ob nonverbale Kommunikationskanäle austauschbar genutzt werden können. Eine umfassende Beschreibung und Dokumentation des Versuchsaufbaus wird zur Verfügung gestellt werden, zur freien Verwendung durch andere Forschende. Zu diesem Zweck werden wir uns bemühen, die Schwellen für die Nutzung des Aufbaus niedrig zu halten und werden dazu auf die Verwendung von kostengünstigen Komponenten und Open-Source Softwarelösungen setzen. Wissenschaftlich und methodisch wird diese Studie das Feld der Blickforschung voranbringen, indem sie es mit multimodaler Kommunikation verbindet und interdisziplinäre Kooperationen unterstützt.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    },
    {
      "project_id": "563112506",
      "url": "https://gepris.dfg.de/gepris/projekt/563112506",
      "title": "WeGaze: Großräumige Blickanalyse via Multi-Kamera-System für soziale Interaktionen",
      "subject_area": "Künstliche Intelligenz und Maschinelle LernverfahrenAllgemeine, Kognitive und Mathematische PsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable ComputingSozialpsychologie und Arbeits- und Organisationspsychologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563112506",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Augenmetriken sind für das Verständnis der menschlichen Kognition, des Verhaltens und der zwischenmenschlichen Dynamik von wesentlicher Bedeutung. Die Verfolgung der Augendynamik mehrerer Personen in großen Räumen auf nicht-invasive Weise ist ein schwieriges technisches Problem. Während Multikamera-Setups vielversprechend sind, um die Genauigkeit und Robustheit in komplexen Umgebungen zu verbessern, wurde die Blickabschätzung mit Multikamerasystemen in der Forschung noch nicht gründlich untersucht. Das ultimative Ziel von WeGaze ist es, die Möglichkeiten der Blick- und Augendynamikforschung zu erweitern, indem wir ein neuartiges System zur Erkennung und Analyse der Augendynamik von mehreren Menschen mit mehreren Kameras in einem großen Raum für naturalistische Einstellungen entwickeln. Unsere Schritte umfassen: (1) Wir nutzen unser einzigartiges Fachwissen über das Multi-View-RGB-Kamerasystem und integrieren den professionellen Eye-Tracker, um einen fortschrittlichen Datensatz von Multi-View-Kameras mit zuverlässigen Grunddaten zu sammeln.(2) Mit den gesammelten Daten werden wir einen neuen Blickschätzungsalgorithmus für Multiview-Kameraeinstellungen entwickeln. (3) Wir entwerfen einen neuen Aufbau zur Erfassung von Interaktionen mit mehreren Teilnehmern in einem großen Raum. (4) Wir erweitern den entwickelten Algorithmus für Mehrpersonen-Szenarien und ermöglichen so eine hochgradige Analyse der Augenbewegungen, einschließlich des gemeinsamen und gegenseitigen Blickverhaltens, in dynamischen, raumbezogenen Umgebungen. (5) Schließlich werden wir das entwickelte Modell in einer Umgebung evaluieren, z. B. in einem mit mehreren Kameras ausgestatteten Raum, in dem mehrere Personen natürliche Unterhaltungen führen. Der entwickelte Algorithmus wird Open Source sein und zunächst an das UGaze Netzwerk verteilt werden. Um seine Benutzerfreundlichkeit zu gewährleisten, werden wir Genauigkeitskriterien festlegen, die sich auf Blickrichtung, Augenblinzeln und interaktionsbasierte Kennzeichnungen wie gegenseitiger Blick und Blickaustausch konzentrieren. Dieses Projekt wird dazu beitragen, die derzeitigen Grenzen der Eye-Tracking-Technologie zu erweitern und die Anwendung von Blickstudien in einem natürlichen Umfeld mit mehreren Personen zu ermöglichen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehenInternationaler BezugNiederlandeKooperationspartnerProfessor Xucong  Zhang, Ph.D."
    },
    {
      "project_id": "563110410",
      "url": "https://gepris.dfg.de/gepris/projekt/563110410",
      "title": "Wie interpretieren und reagieren Primaten auf die Absichten anderer, indem sie deren Blickverhalten beobachten?",
      "subject_area": "Kognitive, systemische und Verhaltensneurobiologie",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 563110410",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2481: \nBlicke verstehen",
      "description": "Primaten verlassen sich in hohem Maße auf visuelle Hinweise, wie Blicke, Kopf- und Körperausdrücke, um soziale Interaktionen zu führen und die Absichten anderer zu erkennen. Diese Fähigkeit ermöglicht eine proaktive Entscheidungsfindung in dynamischen Umgebungen und erlaubt es den Individuen, Aktionen zu antizipieren, anstatt nur zu reagieren. Hier versuchen wir, die wichtigsten Lücken in unserem Verständnis der Rolle der blickbasierten Kommunikation bei der wertbasierten Entscheidungsfindung bei Primaten, insbesondere Rhesusaffen, Rotstirnlemuren und Menschen, zu schließen, indem wir naturalistische, interaktive Szenarien verwenden. Indem wir Makaken in kontrollierten interaktiven Umgebungen untersuchen, werden wir auch die Rolle des parietalen und präfrontalen Kortex beim Erkennen und Handeln der Absichten anderer untersuchen. In den Experimenten werden wir Kopf-, Augen- und Körperbewegungen während Aufgaben verfolgen, bei denen die Individuen die Blicke anderer mit den konkurrierenden Anforderungen einer Verhaltensaufgabe in Einklang bringen müssen. Darüber hinaus werden wir ein prädiktives Computermodell entwickeln, das gated recurrent neural networks (GRUs) verwendet, um zu analysieren, wie Blickhinweise und soziale Dynamik die Entscheidungsfindung beeinflussen. Dieses Modell wird auch als Werkzeug dienen, um die Zusammenarbeit innerhalb von UGaze zu stärken und seine Anwendung auf andere Kontexte auszudehnen, wie z.B. gemeinsame Aufmerksamkeit und Blickdynamik in menschlichen Interaktionen. Durch die Überbrückung von Arten und die Integration fortschrittlicher Methoden werden wir zum Ziel von UGaze beitragen, die Rolle komplexer Blickmuster im sozialen Verhalten zu verstehen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2481: \nBlicke verstehen"
    }
  ]
}