{
  "spp_number": "SPP 2236",
  "spp_title": "Auditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
  "spp_url": "https://gepris.dfg.de/gepris/projekt/422686707",
  "projects_count": 11,
  "projects": [
    {
      "project_id": "444831328",
      "url": "https://gepris.dfg.de/gepris/projekt/444831328",
      "title": "APlausE-MR - Audiovisuelle Plausibilität und und Erleben in Mixed Reality mit mehreren Teilnehmern",
      "subject_area": "AkustikBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable ComputingElektronische Halbleiter, Bauelemente und Schaltungen, Integrierte Systeme, Sensorik, Theoretische Elektrotechnik",
      "funding_period": "Förderung von 2020 bis 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444831328",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Die Forschung in APlausE-MR zu audiovisueller Plausibilität konzentriert sich auf verteilte Mixed-Reality-Szenarien (MR-Szenarien) mit Gruppen von lokalen und an einem anderen Ort befindlichen TeilnehmerInnen. Unsere Hypothese ist, dass realistische audiovisuelle virtuelle Umgebungen hauptsächlich das Gefühl vermitteln an einem virtuellen Ort zu sein. Die Erzeugung und Aufrechterhaltung der Plausibilität der virtuellen Erfahrung erfordert aber insbesondere auch Avatar-Darstellungen, die realistisch aussehen, sich glaubhaft verhalten und anhören. Dazu wird auch die Verwendung von virtuellen Repräsentationen der Teilnehmer auf Basis von 3D-Videoaufnahmen mit klassischen Avatar-artigen Darstellungen verglichen. Darüber hinaus fördert die natürliche Interaktion der Nutzer miteinander und mit der virtuellen Umgebung die Glaubwürdigkeit des Erlebten durch die gemeinsame Wahrnehmung. Diese unterschiedlichen Faktoren verstärken sich gegenseitig im Hinblick auf die Plausibilität des Gesamterlebnisses und können sich bei Unvollkommenheiten sogar gegenseitig kompensieren. Um diese Hypothese zu bestätigen, konzentriert sich unsere Forschung auf drei wesentlichen Herausforderungen: (1) Die Entwicklung und Integration audiovisueller Technologien, die eine plausible Kommunikation in virtuellen Welten ermöglichen, (2) die Identifizierung und Qualifizierung von Faktoren, die die Plausibilität audiovisueller Erfahrungen in Mehrparteien-IVEs beeinflussen, und (3) die Entwicklung geeigneter Bewertungsmethoden und -technologien für die Analyse des Benutzer- und Gruppenverhaltens in lokalen und verteilten audiovisuellen IVEs. Die Doktoranden dieses Projekts werden von drei Forschungsgruppen mit umfangreicher Expertise in Multi-User-Virtual-Reality, immersiver Telepräsenz, realistischen räumlichen Audioerlebnissen und der Beurteilung der Erlebnisqualität in audiovisuellen Umgebungen und für die Multi-Party-Kommunikation unterstützt.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444809588",
      "url": "https://gepris.dfg.de/gepris/projekt/444809588",
      "title": "Audiovisuelle Wahrnehmung von Fahrzeugen in Verkehrssituationen, Phase 2",
      "subject_area": "AkustikAllgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444809588",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "In der zweiten Phase von AUDICTIVE erforscht unser Projekt weiterhin die Rolle der auditiven Wahrnehmung und Kognition für eine sichere Mobilität. Wir untersuchen die Einschätzung der Kontaktzeit (time-to-collision, TTC; \"Wann wird das Fahrzeug an meiner Position ankommen?\") und Straßenüberquerungsentscheidungen aus der Perspektive von Fußgänger*innen. Wir verwenden weiterhin die interaktiven und realistischen audiovisuellen Virtual-Reality-Simulationen von Verbrennen und Elektrofahrzeugen in einem Straßenüberquerungsszenario, die in der ersten Phase implementiert wurden, und werden die Simulationssysteme verfeinern und erweitern. Das Ziel von Arbeitspaket (AP) A ist es, die Wahrnehmungsmechanismen zu verstehen, die dem in Phase 1 beobachteten positiven Effekt des Geräusches von beschleunigenden Fahrzeugen mit Verbrennungsmotor auf die Einschätzung der TTC und Querungsentscheidungen zugrunde liegen. AP B untersucht die auditive Wahrnehmung von Entfernung, Geschwindigkeit und Beschleunigung für den speziellen Fall von sich nähernden Fahrzeugen. Ziel ist es, die in Projektphase 1 und in AP A beobachtete Gewichtung von Hinweisreizen bei der TTC-Schätzung und Querungsentscheidungen auf der Grundlage der auditorischen Sensitivität in den Basisaufgaben und in Abhängigkeit von der Verfügbarkeit spezifischer akustischer Hinweisreize zu erklären. Da die Ergebnisse aus Phase 1 einen signifikant geringeren Nutzen des Geräusches von beschleunigenden Elektrofahrzeugen zeigten, selbst mit akustischen Fahrzeugwarnsystemen (AVAS), wird in AP C untersucht, wie AVAS-Designs so verbessert werden können, dass sie Beschleunigungsinformationen genauso effektiv wie das Geräusch eines Verbrenners liefern. Die Plausibilität der Verkehrsszenarien, die in einem Virtual-Reality-System dargestellt werden, kann bei den Verkehrssicherheits- und Sound-Quality-Untersuchungen eine wichtige Rolle spielen. Die Komplexität der VR-Umgebung hat einen Einfluss auf die wahrgenommene Gesamtplausibilität dieser Virtual-Reality Simulationen. Die Auswirkung der Komplexität auf Plausibilitätsbewertungen und das Verhalten in Experimenten zur TTC-Schätzung und zu Querungsentscheidungen wird untersucht. Zunächst wird in AP D die Komplexität der virtuellen Schallquellen erhöht, indem die Richtcharakteristiken der Teilquellen von Fahrzeugen berücksichtigt werden. Dazu wird eine neue Aufnahmemethode entwickelt, auf deren Grundlage neue virtuelle Quellenmodelle erstellt werden. AP E konzentriert sich auf die Komplexität der Szeneninhalte, von einer leeren Straße bis hin zur Komplexität einer belebten Straße, und den Einfluss der auditiven Simulationsgenauigkeit auf die Plausibilität. Schließlich wird in AP F der Einfluss zusätzlicher technischer und sozialer Ablenkungsfaktoren auf die Plausibilitätsbewertung und das Verhalten der Versuchspersonen untersucht, indem ihnen zusätzliche Aufgaben mit Smartphones oder Interaktionen mit Menschen während der Verkehrssicherheitsexperimente gegeben werden.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444832396",
      "url": "https://gepris.dfg.de/gepris/projekt/444832396",
      "title": "Einfluss des Audio-Renderings in virtuellen Umgebungen auf Realismus, Präsenz und sozio-kognitive Verarbeitung",
      "subject_area": "AkustikPersönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444832396",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Interaktive virtuelle Umgebungen (IVUs) eröffnen einzigartige neue Möglichkeiten, Prozesse der Wahrnehmung und der sozio-kognitiven Verarbeitung in komplexen Szenen zu erforschen, da eine hohe ökologische Validität mit einem hohen Maß an experimenteller Kontrolle einhergehen kann. Obwohl Forschende auditorische Stimuli dabei oft mitberücksichtigen, ist die Integration moderner hochrealistischer Audio-Renderings immer noch die Ausnahme. Das übergreifende Ziel dieses Projekts ist, zum einen die technischen Anforderungen an das binaurale  Audio-Rendering über Kopfhörer zum Erreichen hochrealistischer audiovisueller Darbietungen von virtuellen sozialen Szenen zu identifizieren, und zum anderen den Einfluss des Audio-Renderings auf soziale Präsenz und sozio-kognitive Prozesse wie Emotionen, Empathie und soziale Angst zu bestimmen. Während in der ersten Förderperiode das Hauptaugenmerk auf der Erzielung des höchstmöglichen Realismus lag, wird der Schwerpunkt in der zweiten Förderperiode darauf gerichtet sein, das Wechselspiel zwischen top-down-Effekten und Stimulus-abhängigen bottom-up-Effekten in virtuellen sozialen Interaktionsszenarien zu erforschen, wobei sowohl verhaltensbezogene als auch neuralen Antworten (über EEG) gemessen werden. Konkret werden Erwartungshaltungen, Emotionen, Gewöhnungseffekte, sozialer Stress und Präsenz sowie höhere soziale Kognitionsmechanismen (z.B. Empathie) in virtuellen sozialen Szenen mit unterschiedlichen Qualitätsstufen des binauralen Audio-Rendeirngs betrachtet und analysiert. Letzteres baut auf dem hochrealistsichen Rendering aus Phase 1 auf, und soll zum Rendering multipler Geräuschquellen eines virtuellen Auditoriums sowie zur verbesserten Wiedergabe der eigenen Stimme in virtuellen Szenen weiterentwickelt werden, um damit noch lebensnahere Interaktionen in virtuellen sozialen Szenen zu ermöglichen. Zusätzlich werden Gewöhnungs- und Trainingseffekte sowie Alternativen zur Nachverfolgung der Kopfausrichtung mit dem Ziel untersucht, in Zukunft den Zugang zur Verwendung von IVUs zu erleichtern sowie um weitergehende klinische Anwendungen wie eine verbesserte Therapie von Angststörungen verfolgen zu können. Zusammengefasst wird dieses Projekt zum besseren Verständnis psychologischer und physiologischer Prozesse sowie deren Bedeutung zur Erzeugung plausibler Repräsentationen realer Umgebungen beitragen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444697733",
      "url": "https://gepris.dfg.de/gepris/projekt/444697733",
      "title": "Evaluierung auditiver Kognition in Klassenräumen für verschiedene Altersgruppen, von Vorschulkindern bis zu Erwachsenen, mit Hilfe audiovisueller virtueller Realität - EArAge-VR",
      "investigators": "Professorin Dr.-Ing. Janina  Fels;Professorin Dr. Maria  Klatte;Professor Dr.-Ing. Alexander  Raake",
      "subject_area": "AkustikAllgemeine, Kognitive und Mathematische PsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable Computing",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444697733",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Im Fortsetzungsantrag EArAge-VR werden wir audiovisuelle immersive virtuelle Umgebungen für die Evaluierung auditiver Kognition in Klassenraumszenarien untersuchen und die Realitätsnähe der Forschungsmethodik schrittweise erhöhen.  Das vorhandene Wissen über die Auswirkungen von Klassenraumumgebungen auf die kognitive Leistungsfähigkeit basiert überwiegend auf auditiven oder teilweise auch visuellen Untersuchungen. Da diese keine realen Alltagssituationen abbilden, ist der Bedarf an kombinierten, realitätsnahen audiovisuellen Untersuchungen hoch. In EArAge-VR wollen wir (1) audiovisuelle Klassenraumszenarien und Evaluierungsinstrumente (Leistungsmessungen und Fragebögen zur Qualität des Erlebens, QoE) erstellen, validieren und für die Forschung in verschiedenen, auch weniger technologieorientierten Einrichtungen zur Verfügung stellen. Parallel dazu wollen wir (2) weitere Einblicke in die Prozesse und Mechanismen gewinnen, die der auditiven kognitiven Leistung in komplexen Klasssenraumumgebungen zugrunde liegen, und (3) diesbezügliche Entwicklungsveränderungen zwischen Vorschul- und Erwachsenenalter untersuchen. Basierend auf den Ergebnissen des ECoClass-VR-Projekts aus der ersten Phase von AUDICTIVE werden wir eine Auswahl der dort erstellten und evaluierten Paradigmen verwenden. Damit können wir die auditive Kognition in Bezug auf die Sprachwahrnehmung, das Hörverständnis und die hörbezogene Szenenanalyse in virtuellen Klassenräumen bei Kindern und Erwachsenen analysieren. Die dort erstellten auditiven und visuellen Szenen werden kombiniert und schrittweise zu noch realistischeren, alltagsnahen Klassenraumszenarien erweitert. Dies beinhaltet eine dynamische akustische Wiedergabe, eine audiovisuelle Integration und eine verstärkte Interaktion mit den virtuellen Szenen. Angesichts der in der ersten Phase festgestellten überproportionalen Auswirkungen von Geräuschszenarien im Klassenraum auf die Hörleistung von Zweitklässlern im Vergleich zu Drittklässlern und Erwachsenen wird die Stichprobe darüber hinaus auf Vorschul- und Erstklässler sowie Nicht-Muttersprachler erweitert. Um kleine Kinder, die keine Head-Mounted Displays tragen können, in einer immersiven Umgebung testen zu können, werden wir alternative Versuchsanordnungen mit umgebenden Bildschirmen schaffen. Dies ermöglicht einen Vergleich der Entwicklungsveränderungen in Bezug auf die auditive Kognition sowie der erhobenen indirekten Indikatoren für die Qualität des Erlebens zwischen den Altersgruppen. Durch die Betrachtung der gesammelten Daten aus beiden Projektphasen, ECoCLass-VR und EArAge-VR, werden wir auch in der Lage sein, gemeinsame Schlussfolgerungen zu ziehen und Empfehlungen für die weitere Forschung zu geben, mit dem Ziel einer zukünftigen Standardisierung der Testparadigmen, die sich als am geeignetsten erwiesen haben, um Auswirkungen der Szenenkomplexität und Entwicklungsveränderungen zwischen den Altersgruppen zu identifizieren.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVEMitverantwortlichProfessor Dr. Thomas  Lachmann"
    },
    {
      "project_id": "444832250",
      "url": "https://gepris.dfg.de/gepris/projekt/444832250",
      "title": "EVOLVE-QoE - Gültigkeitsbewertung von interaktiven virtuellen Umgebungen: Ein Rahmenwerk zur Qualität des Erlebens audiovisueller Szenen",
      "subject_area": "Akustik",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444832250",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Das EVOLVE-QoE Projekt baut auf das QoEVAVE Projekt aus AUDICTIVE Phase 1 auf und zielt darauf ab, die Wissenslücke bezüglich geeigneter audiovisueller Szenencharakteristika in interaktiven virtuellen Umgebungen (IVU) zu schließen. Insbesondere soll untersucht werden, worin sich Interaktive Reale Umgebungen (IRU), d.h. die reale Welt, und IVU voneinander unterscheiden und welche der jeweiligen Eigenschaften Veränderungen der auditiven Kognition in komplexen, realitätsnahen audiovisuellen Szenen hervorrufen. EVOLVE-QoE verfolgt einen systematischen Ansatz, um audiovisuelle Szenen zu annotieren, zu analysieren und zu bewerten. Dabei werden sowohl menschbasierte Top-Down-Ansätze als auch instrumentelle Bottom-Up-Ansätze verwendet. Der Top-Down-Ansatz beinhaltet Explorationsmuster durch 3-DoF- bis 6-DoF-Trajektorien, Eye-Tracking und Befasstheit (Engl. Engagement) und liefert weitere vom Menschen generierte Annotationen, die auf kognitiven Prozessen basieren. Der Bottom-up-Ansatz untersucht audiovisuelle Szenenanalyse, Komplexitätsmodelle und instrumentelle Deskriptoren. EVOLVE-QoE greift Aspekte der Soundscape- und visuellen Szenenanalyse auf und erforscht Methoden zur Bewertung der ökologischen Validität von IVU. Das Projekt zielt darauf ab, ein geeignetes Schema bereitzustellen zur Charakterisierung von IVU innerhalb eines umfassenden methodischen Rahmenwerks für die Bewertung der Qualität des Erlebens (Quality of Experience, QoE). Die Hauptziele von EVOLVE-QoE sind i) die Erweiterung der IVU-Szenendatenbank (https://qoevave.github.io/database/) mit reichhaltigeren 3-DoF- und 6-DoF-explorierbaren VR-Szenen, einschließlich Szenen mit einer jeweiligen realen Entsprechung für die Untersuchung der ökologischen Validität; ii) Szenen mit von Menschen erzeugten Annotationen, die Aspekten audiovisueller Kognition sowie Explorationsmustern ansprechen; iii) die Eignung instrumenteller Methoden für die Szenencharakterisierung zu untersuchen und mit menschenbasierten Annotationen zu vergleichen; iv) die systematische Evaluierung der ökologischen Validität, die mit IVU im Vergleich zu IRU erreicht wird, unter Verwendung der bestmöglichen Auswahl von menschbasierten und instrumentellen Methoden; und v) Integration aller Datenbanken, Werkzeuge und Ergebnisse in das konzeptionelle und datenbezogene Rahmenwerk von QoEVAVE/EVOLVE-QoE zur Förderung von Praktíken der offenen Wissenschaft (Engl. Open Science). Zusammengefasst zielt das EVOLVE-QoE-Projekt darauf ab, den Wissensstand zu geeigneten audiovisuellen Szenencharakteristika in der IVU-Forschung signifikant voranzutreiben und zur Entwicklung eines umfassenden Rahmenweks für die QoE-Evaluierung beizutragen. Das Projekt adressiert alle drei Schwerpunkte von AUDICTIVE, von Interaktiven Virtuellen Umgebungen (b) über die auditive Kognition bis hin zu Qualitätsevaluationsmethoden (c).DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444724862",
      "url": "https://gepris.dfg.de/gepris/projekt/444724862",
      "title": "Kognitive Leistungen beim Zuhören in komplexen audiovisuellen Kommunikationssituationen mit virtuellen Agenten: Untersuchungen zu Aufmerksamkeit, Erinnerungsleistung und Höranstrengung (exAMPLE)",
      "investigators": "Professorin Dr.-Ing. Janina  Fels;Professor Dr. Torsten Wolfgang  Kuhlen;Professorin Dr. Sabine Janina  Schlittmeier",
      "subject_area": "AkustikAllgemeine, Kognitive und Mathematische PsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable Computing",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444724862",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Von Angesicht zu Angesicht zu kommunizieren ist die häufigste Form des verbalen Informationsaustauschs. Dabei stehen Zuhörer*innen bei Gesprächen zwischen mehreren Sprecher*innen in komplexen und dynamischen Umgebungen wie Großraumbüros oder belebten Bars vor besonderen Herausforderungen: Diese Umgebungen sind akustisch komplex, multisensorisch vielfältig und dynamischer Natur. Welche Auswirkungen diese Einflussfaktoren auf das Verstehen und Erinnern inhaltlicher Fakten von Gesprächen zwischen zwei oder mehr Sprecher*innen haben und inwieweit das Anfertigen von Gesprächsnotizen die kognitive Zuhörleistung unterstützen kann, ist noch weitgehend unerforscht. Das Ziel dieses Forschungsvorhabens ist es, audiovisuelle Variationen realistischer Hörsituationen in Virtueller Realität (VR) zu untersuchen und ihre Auswirkungen auf die Aufmerksamkeit der Zuhörer*innen, die Sprachverständlichkeit, das Hörverstehen sowie das Gedächtnis für Gesprächsinhalte und andere sprecherbezogene Aspekte (z.B. wer etwas gesagt hat) zu untersuchen. Aufbauend auf unserem Vorgängerprojekt geht dieses Projekt weg von vereinfachten und hin zu komplexen audiovisuellen, immersiven Umgebungen mit vielfältigen und lebhaften audiovisuellen Szenarien. Zusätzlich erweitern wir den Umfang der betrachteten kognitiven Leistungen vom Verstehen und Erinnern von Gesprächsinhalten auf das Anfertigen von angeleiteten Notizen sowie um das Erinnern zusätzlicher Gesprächsaspekte und die Aufmerksamkeitszuwendung und -lenkung zu den Sprecher*innen. Hierfür entwickeln wir immersive und interaktive audiovisuelle virtuelle Umgebungen, in denen die Zuhörer*innen an Gesprächen zwischen zwei oder mehr Sprecher*innen teilnehmen, die als virtuelle Agent*innen dargestellt werden. Anschließend wird die Erinnerungsleistung für gehörte Gesprächsinhalte und weitere gesprächsbezogene Aspekte erfasst. Dazu wird das Heard Text Recall (HTR) Paradigma aus unserem Vorgängerprojekt entsprechend erweitert und angepasst, um auch sprecherbezogene Aspekte (TR) abzufragen und das Anfertigen von Notizen (NT) während des Zuhörens zu operationalisieren. Damit werden die erweiterten Zuhöraufgaben HTR-TR und HTR-NT entwickelt. Durch die Untersuchung der Effekte verschiedener Merkmale der audiovisuellen VR auf die oben genannten kognitiven Leistungen möchten wir wichtige Erkenntnisse für die Schaffung realistischer und immersiver verbaler sozialer Interaktionen gewinnen und somit zur aktuellen VR-basierten Kognitionsforschung beitragen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444827755",
      "url": "https://gepris.dfg.de/gepris/projekt/444827755",
      "title": "Kognitive und signalgetriebene Faktoren in der Wahrnehmung von statischen und dynamischen Abständen",
      "investigators": "Dr. Stephan  Ewert;Dr. Virginia  Flanagin;Professor Dr. Steven van de Par",
      "subject_area": "Akustik",
      "funding_period": "Förderung von 2020 bis 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444827755",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Die auditorische Distanzwahrnehmung (ADW) ist ein wichtiger Bestandteil der räumlichen Wahrnehmung und von zentraler Bedeutung für die Bewertung und Vermeidung potenzieller Bedrohungen. Während der Sehsinn auf nicht verdeckte Objekte im Gesichtsfeld beschränkt ist, stellt das Gehör omnidirektionale Informationen zur Verfügung. Durch den großen Einfluss von Quelle und akustischer Umgebung auf die sensorischen Reize ist die ADW gegenüber der Richtungslokalisierung in der Horizontalebene, die interaurale Reize nutzen kann, allerdings erschwert. Zur ADW tragen Pegel, Direktschall-zu-Nachhall-Verhältnis, und bis zu einem gewissen Grad spektrale Effekte bei, was insgesamt Kenntnisse oder Annahmen über die Umgebung erfordert. Trotzdem scheint die ADW im Alltag zuverlässig zu funktionieren.Ziel dieses Projekts ist es, die statische und dynamische ADW und ihre Rolle bei der Raumwahrnehmung und Navigation besser zu verstehen. In Anbetracht der möglichen Variabilität der sensorischen Reize nehmen wir an, dass kognitive Einflüsse auf die ADW existieren, aufgrund von i) vorheriger Erfahrung mit einer akustischen Umgebung, ii) emotionaler Valenz (Bedrohungspotential) der Quelle und iii) visuellen Informationen über die Szene. Wir gehen ferner davon aus, dass die ADW wichtige Hinweise für die Navigation liefern und die Darstellung des Raums unterstützen kann.Wir verwenden modernste Techniken für virtuelle Realität (VR) und verbinden eine Videospiel-Engine für visuelles Rendering mit unserer eigenen angepassten und optimierten Raumakustiksimulation. Neben psychoakustischen Messungen identifizieren wir beteiligte Hirnregionen mit funktioneller Magnetresonanztomographie (MRT). Um auf VR basierende Studien innerhalb der technischen Grenzen von MRT-Versuchen zu ermöglichen, entwickeln wir ein modulares virtuelles Szenario, das die Körperhaltung und eingeschränkte Wahrnehmung akustischer Reize im Tomographen berücksichtigt und eine plausible Manipulation der akustischen Umgebung, der emotionalen Valenz der Quelle und der Verfügbarkeit von Seheindrücken zulässt.Wir tragen zu allen Bereichen des SPP Audictive bei. Zur “auditory cognition” untersuchen wir die Wirkung der drei Faktoren Vertrautheit mit der akustischen Umgebung, emotionale Valenz und visuelle Informationen auf die ADW. Wir untersuchen die Interaktion von Eigenbewegung mit ADW und identifizieren mittels fMRT neuronale Korrelate. Zu \"interactive virtual Environments\" verbessern wir unseren Raumakustiksimulator, hin zu einer rechnerisch effizienten, perzeptuell evaluierten Methode zur Simulation von Distanz und Bewegung in verschiedenen Situationen. Wir werden zwei interaktive Szenarien entwickeln, die auf den Einsatz im Tomographen optimiert sind. Zu \"quality evaluation methods\" bewerten wir die entwickelten virtuellen Szenarien direkt durch psychoakustische Methoden und Bildgebung des Gehirns, sowohl für sich als auch im Vergleich zur realen akustischen Stimulation.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444532506",
      "url": "https://gepris.dfg.de/gepris/projekt/444532506",
      "title": "Koordinationsfonds",
      "subject_area": "AkustikAllgemeine, Kognitive und Mathematische PsychologieBild- und Sprachverarbeitung, Computergraphik und Visualisierung, Human Computer Interaction, Ubiquitous und Wearable Computing",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444532506",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "In den letzten Jahren hat sich unser Verständnis von auditiven kognitiven Prozessen erheblich verbessert - von Wahrnehmung, Aufmerksamkeit und Gedächtnis bis zu komplexen Leistungen wie Szenenanalyse und Kommunikation. AUDICTIVE zielt auf Grundlagenforschung zu den drei Forschungsschwerpunkten ab: (a) \"auditive Kognition\", (b) \"interaktive audiovisuelle virtuelle Umgebungen\" und (c) \"Qualitätsbewertungsmethoden\", wobei letztere an der Schnittstelle zwischen (a) und (b) angesiedelt sind. Die erste Phase von AUDICTIVE konzentrierte sich vor allem auf die Übertragung der gut kontrollierten, aber oft unrealistischen Stimuluspräsentationen, die in der auditiven Kognitionsforschung verwendet werden, auf umfassendere virtuelle oder Mixed-Reality-Umgebungen. Hier spiegelten sich die jüngsten Entwicklungen in der Hard- und Softwaretechnologie wider, wobei die audiovisuelle virtuelle und gemischte Realität (VR, MR) ein hohes Maß an Wahrnehmungsplausibilität erreichte. Auf Basis der Ergebnisse der ersten Phase zielt die zweite Phase von AUDICTIVE darauf ab, geeignete Paradigmen zu identifizieren oder (weiter) zu entwickeln, um sie in realistischeren Szenen zu nutzen, mit dem Ziel, natürliche Wahrnehmung, Erfahrung und/oder Verhalten hervorzurufen. In der zweiten Phase von AUDICTIVE wollen wir deshalb den wissenschaftlichen Kenntnisstand, die Theorien und Modelle, die in der auditiven Wahrnehmungs- und Kognitionsforschung entwickelt wurden, auf noch realistischere Alltagssituationen ausweiten. Hier sollen neue Erkenntnisse, Methoden und Techniken (z. B. psychometrische und kognitive Bewertung, Bewertung der Lebensqualität, physiologische oder verhaltensbezogene Analyse, Signalerfassung und -analyse, Verbesserung der VR/MR-Technologie) für reichhaltigere und komplexere Szenarien unter Einbeziehung interaktiver VR- und/oder MR-Technologie entwickelt werden. Das Koordinationsprojekt wird einen offenen wissenschaftlichen Ansatz fördern, um eine umfassende Ergebnisdatenbank zu entwickeln. Alle Projekte sollen eine Evaluierung der Qualität von VR- und/oder MR-Umgebungen für die Erforschung der auditiven Kognition oder der Validität von Forschungsergebnissen zur auditiven Kognition in VR- und/oder MR-Umgebungen beinhalten und alle Projekte müssen zum zentralen Forschungsdatenmanagement beitragen. Darüber hinaus wird das Koordinationsprojekt das Forschungsdatenmanagement in der Praxis testen, indem ein Ringversuch an verschiedenen Einrichtungen durchgeführt wird. An diesem Punkt wird ein gutes FDM sichtbar und offensichtlich. Denn ein guter Austausch von Experimenten, Szenen und der verwendeten Technik ist nur möglich, wenn die einzelnen Schritte gut dokumentiert und offen verfügbar sind. Zusätzlich wird das Koordinationsprojekt eine Buchpublikation koordinieren, die die Ergebnisse aus beiden Förderperioden einem breiten Publikum zugänglich machen soll.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444761144",
      "url": "https://gepris.dfg.de/gepris/projekt/444761144",
      "title": "Kortikale und Verhaltenmaße der aktiven Kommunikation",
      "subject_area": "AkustikBiologische PsychiatrieMedizinische Physik, Biomedizinische Technik",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444761144",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Unser Verständnis der auditiven Sprachverarbeitung beruht auf Laborexperimenten mit einfachen Reizen, die reale Szenarien nicht hinreichend abbilden. Während der Einfluss des Lippenlesen etwa bekannt ist, wurde der audiovisuellen Verarbeitung in komplexen Kommunikationsszenarien mit sozialen Interaktionen nicht viel Aufmerksamkeit geschenkt. Reale Kommunikation beinhaltet Körperbewegungen, Gesten, Gesichtsausdrücken und Augenblinzeln, was in Laborexperimenten, bei denen eine zuhörende Person passiv bleibt, nicht gut abgebildet ist. Wir entwickeln interaktive virtuelle Umgebungen (VU), um reproduzierbare realistische audiovisuelle Szenarien zu nutzen. VUs verbinden das Ziel der Reproduzierbarkeit der Ergebnisse mit dem Anspruch die Komplexität alltäglicher Kommunikationsanforderungen. Unser Ziel ist es, audiovisuelle Sprachverarbeitung besser zu verbessern, indem wir VEs entwickeln und evaluieren, die zumindest einen Teil der Komplexität natürlicher Kommunikationssituationen nachahmen und den Zuhörer als aktiven Akteur einbeziehen. Auf neuronaler Ebene kann die zeitliche Dynamik der auditiven Aufmerksamkeit auf Sprache mit der Elektroenzephalographie (EEG) untersucht werden. Die kortikale Sprachverfolgung mit EEG wurde in der ersten Phase dieses Projekts in nicht interaktiven VE implementiert und ermöglichte uns eine objektive Bewertung des aufmerksamen Zuhörens. Insbesondere fanden wir heraus, dass die kortikale Sprachverfolgung gültige Ergebnisse für nicht spontane, vorab aufgezeichnete Sprache lieferte, die in einer VU präsentiert wurden. In der zweiten Phase werden wir VUs weiterentwickeln, um reale und Telepräsenzbedingungen zu simulieren. Dies ermöglicht die Untersuchung von interaktiven Kommunikationsszenarien. In Studie 1 vergleichen wir passives Zuhören mit einem aktiven Gespräch in einem dyadischen Kommunikationsszenario und manipulieren die Gesprächsbeteiligung (aktiv vs. passiv) und die visuelle Darstellung der Gesprächspartner (reale Präsenz vs. Telepräsenz). In Studie 2 werden wir die auditive Verarbeitung und die Verhaltenssynchronisation zwischen vertrauten und unbekannten Gesprächspartnern anhand triadischer Kommunikationsszenarien untersuchen. Wir werden den Faktor der Bekanntheit des Gesprächspartners einführen und den Einfluss der visuellen Darstellung des Gesprächspartners (reale Präsenz vs. Telepräsenz) auf die auditive Verarbeitung und Synchronisation untersuchen. In Studie 3 werden auditive Verarbeitung und Verhaltenssynchronisation in triadischen Situationen in Gegenwart audiovisueller Ablenkungsszenarien untersucht und so die Kommunikationsschwierigkeit manipuliert. In allen drei Studien verwenden wir das EEG als nicht-invasives Mittel zur Überwachung der Aufmerksamkeit auf Sprach- und Nicht-Sprachsignale. Messungen der Verhaltenssynchronisation zwischen sich unterhaltenden Personen werden analysiert, um den Kommunikationsaufwand vorherzusagen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVEMitverantwortlichDr. Giso  Grimm"
    },
    {
      "project_id": "444873001",
      "url": "https://gepris.dfg.de/gepris/projekt/444873001",
      "title": "Mechanismen der Aufmerksamkeit und Integration entlang der drei Dimensionen des auditiven Raums",
      "subject_area": "AkustikKognitive und systemische Humanneurowissenschaften",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444873001",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Unser auditorisches System verarbeitet akustische und nichtakustische Reize, um eine Orientierung in komplexen multimodalen Umgebungen zu ermöglichen und sich an Veränderungen in dieser Umwelt anzupassen. Je nachdem, in welchen räumlichen Dimensionen (Azimut, Höhe, Entfernung) und Modalitäten (auditiv, visuell, haptisch) sie sich unterscheiden, variieren diese Reize in ihrer Repräsentation im Gehirn, in der Zeit, in der sie dem auditorischen System zur Verfügung stehen, in ihrer räumlichen und zeitlichen Auflösung und Genauigkeit sowie in ihrer Rolle bei der Steuerung von Aufmerksamkeit. Um diese Effekte zu untersuchen, schlagen wir vor, multimodale virtuelle Umgebungen zu verwenden, um Szenen unterschiedlicher Komplexität zu generieren und Reize entweder isoliert oder in Kombination mit Reizen aus anderen räumlichen Achsen und Wahrnehmungs-modalitäten zu präsentieren. In diesen synthetischen Umgebungen werden wir Spatial unmasking, Lokalisierung und die Segregation von Sprache in Sprache bestimmen, also Phänomene, die bisher meist nur in der horizontalen Ebene untersucht wurden, und beobachten, wie Bewegungen von Target oder Masker diese Effekte beeinflussen. Wir werden neuronale Korrelate der Zuweisung von Aufmerksamkeit und der Integration von räumlichen und zeitlichen Reizen aus EEG-Aufzeichnungen identifizieren, und untersuchen, inwieweit ein visueller Input und Kopfbewegungen die Fähigkeit unterstützen, Aufmerksamkeit zu fokussieren und inwieweit die Sprachkommunikation durch multimodale Interaktionen akustischer, visueller und haptischer Art verbessert werden kann. In psychoakustischen Experimenten werden wir die Zuordnung von Aufmerksamkeit und die kognitive Belastung durch die Analyse von EEG-Signalen, Spatial release from masking und Listening effort werden wir durch Tests zur Sprachverständlichkeit und Pupillometrie bestimmen. Aufgrund ihrer Alltagsrelevanz werden wir uns auf Speech-in-speech-Szenarien konzentrieren. Wir gehen davon aus, dass sich die Zusammenarbeit zweier Gruppen mit sich teilweise überschneidenden und teilweise komplementären Expertisen in der Akustik und den Neurowissenschaften im vorgeschlagenen Projekt als ebenso fruchtbar erweisen wird wie im Projekt der ersten Phase. Wiederum sollen die binauralen Stimuli von der Berliner Gruppe generiert und EEG-Experimente, die auf diesen Stimuli basieren, von der Leipziger Gruppe durchgeführt werden. Die psychoakustischen Experimente sollen in Zusammenarbeit beider Gruppen in einer klassischen Laborumgebung und in speziell entworfenen interaktiven virtuellen Umgebungen durchgeführt werden. Darüber hinaus haben wir, in Zusammenarbeit mit zwei Arbeitsgruppen in Oldenburg, ein Arbeitspaket der Entwicklung von Werkzeugen gewidmet, die innerhalb von AUDICTIVE als wertvoll für die gesamte Community identifiziert wurden, etwa Entwicklung eines standardisierten Werkzeugs für das Rendering und den Austausch von räumlichen, auditiven Szenen und Stimuli.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    },
    {
      "project_id": "444777670",
      "url": "https://gepris.dfg.de/gepris/projekt/444777670",
      "title": "Untersuchung auditiver und audio-visueller Bewegungswahrnehmung in realen und virtuellen 3D-Umgebungen sowie der Einflüsse von Aufmerksamkeit und Training",
      "subject_area": "AkustikAllgemeine, Kognitive und Mathematische PsychologieKommunikationstechnik und -netze, Hochfrequenztechnik und photonische Systeme, Signalverarbeitung und maschinelles Lernen für die Informationstechnik",
      "funding_period": "Förderung seit 2020",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 444777670",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE",
      "description": "Moderne Arbeitsumgebungen sind durch eine zunehmende Automatisierung gekennzeichnet, bei der autonom agierende Roboter sich ein gemeinsames Arbeitsumfeld mit Menschen teilen. Da bewegte Roboter ein Sicherheitsrisiko darstellen können, ist ein genaues Verständnis der Wahrnehmung von und Interaktion mit bewegten Objekten von großer Bedeutung. Dies gilt insbesondere dann, wenn bewegte Objekte sich nicht im Sichtfeld des Menschen befinden. Hier bieten moderne VR-Technologien die Möglichkeit, (Arbeits-)Umgebungen im Hinblick auf sichere und effiziente Arbeitsabläufe zu simulieren und zu evaluieren. Hierzu werden in diesem Projekt neben Verhaltensmaßen besonders auch EEG-Korrelate der zugrundeliegenden neuro-kognitiven Prozesse sowie subjektive Maße (z.B. zur Quantifizierung der Plausibilität der VR-Umgebung oder der wahrgenommenen Schwierigkeit der Aufgabe) in realen und virtuellen Umgebungen analysiert und verglichen. Wir knüpfen somit an die Erkenntnisse unseres Projekts in der ersten Phase des DFG-Schwerpunktprogramms \"AUDICTIVE\" an, in der eine VR-basierte audio-visuelle Testumgebung zur Untersuchung der räumlichen Wahrnehmung und Aufmerksamkeit im dreidimensionalen Raum entwickelt und validiert wurde. Der Fokus liegt nun auf der Erforschung der Bewegungswahrnehmung in simulierten realen und virtuellen Arbeitsumgebungen und der Validierung der audio-visuellen und auditiven Bewegungswahrnehmung in VR. Dabei werden dynamische Komponenten in die reale und virtuelle Umgebung der ersten Phase integriert und Experimente zur Untersuchung der Bewegungswahrnehmung in beiden Umgebungen durchgeführt. Auf Grundlage früherer Ergebnisse werden die Rolle der Eingewöhnung in die Raumakustik und die Auswirkung der Aufmerksamkeit auf die Wahrnehmung von mehreren bewegten Schallquellen untersucht. Es wird ein Doppelaufgabenparadigma verwendet, bei der die mentale Beanspruchung der Teilnehmenden durch eine zweite unabhängige Aufgabe in Gegenwart bewegter Objekte erhöht wird. Schließlich wird mit Blick auf eine mögliche Nutzung der VR-Technologie für das Training von realen Handlungssequenzen der Effekt von audio-visuellem Training auf die Wahrnehmung von bewegten auditiven Objekten untersucht und mögliche Transfers zwischen beiden Umgebungen abgeleitet. Es werden junge und ältere Menschen einbezogen, um mögliche altersbedingte Einflüsse zu ermitteln. Schließlich werden wir die entwickelte VR-Plattform zur Untersuchung binauraler Algorithmen für die Sprachsignalverbesserung (z.B. Enthallung) nutzen und deren Einfluss auf die räumliche Wahrnehmung untersuchen. Somit werden in diesem Projekt neue Erkenntnisse in der neuro-kognitiven Verarbeitung audio-visueller Bewegungsinformationen erarbeitet und einer verbesserten Arbeitssicherheit durch Verwendung von VR-Technologien der Weg bereitet.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2236: \nAuditive Kognition in interaktiven virtuellen Umgebungen – AUDICTIVE"
    }
  ]
}