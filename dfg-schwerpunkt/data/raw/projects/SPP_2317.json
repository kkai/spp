{
  "spp_number": "SPP 2317",
  "spp_title": "META-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
  "spp_url": "https://gepris.dfg.de/gepris/projekt/441890184",
  "projects_count": 21,
  "projects": [
    {
      "project_id": "464547651",
      "url": "https://gepris.dfg.de/gepris/projekt/464547651",
      "title": "Anwendung von Validitätsprinzipien in Metastudien zur Überprüfung von Kausalbeziehungen",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieSozialpsychologie und Arbeits- und Organisationspsychologie",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464547651",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Metastudien wurden als Methode vorgeschlagen, um die Replizierbarkeit und Generalisierbarkeit experimenteller Ergebnisse durch Überprüfung von potentiellen Moderatoren zu testen. Diese Methode umfasst die Durchführung einer Reihe von Studien mit wenigen Probanden, in denen jeweils die Eigenschaften der Aufgaben modifiziert und diverse Probandenstichproben einbezogen werden. Dieser Ansatz, der auch unter dem Begriff der radikalen Randomisierung firmiert, entfernt sich von klassischen experimentellen Studien, in denen die Eigenschaften von Manipulationen und Messinstrumenten in der Regel nicht variiert werden. Metastudien führen zu einem nuancierterem Verständnis der untersuchten Phänomene, was zur Theorieentwicklung beiträgt. In unserem Antrag erweitern wir die Methode von Metastudien, indem wir Validitätsprinzipien berücksitigen, die im aktuellen Ansatz bisher wenig Beachtung finden. Wir konzentrieren uns auf zwei Schlüsselaspekte in unserer Erweiterung von Metastudien: die Überprüfung der Wirksamkeit von Manipulationen und die funktionalen Beziehungen zwischen der unabhängigen und der abhängigen Variablen. Unsere Demonstration der Erweiterung wird sich auf zwei häufig manipulierte Konstrukte konzentrieren: intuitive kognitive Verarbeitung und Affekt. Wir werden den kausalen Zusammenhang der beiden Konstrukte zu Kooperationsverhalten untersuchen. Replikationsstudien und Metaanalysen haben gemischte Ergebnisse für die Beziehung zwischen Intuition und Kooperation gezeigt, was teilweise auf Validitätsprobleme zurückgeführt werden könnte. Um die Konstruktvalidität von Manipulationen zu bewerten, werden wir in Pilotstudien die Wirksamkeit verschiedener Manipulationen von Intuition und Affekt untersuchen und diese Manipulationen in unserer Metastudie nutzen. Um die statistische Konklusionvalidität zu erhöhen, werden wir einen kürzlich vorgeschlagenen maschinellen Lernansatz nutzen. Dieser Ansatz kann im Prinzip jede funktionale Beziehung zwischen Manipulationen und Maßen erfassen, was einen Vorteil gegenüber typischen statistischen Modellen mit (oftmals linearen) Funktionen bietet. Mit den Ergebnissen unserer Metastudie planen wir, mithilfe von Computersimulationen Replikationsraten und Replikationseffektgrößen für unsere kausale Beziehung vorherzusagen. Um unsere Ergebnisse weiter zu validieren, haben wir eine Replikationsstudie geplant, um Vorhersagen über Effektgrößen zu testen, die aus diesen Simulationen abgeleitet wurden. Unser Antrag zielt darauf ab, zu verstehen, warum Effektgrößen in Replikationsstudien variieren und wie Methoden zur Vorhersage dieser Größen basierend auf den Eigenschaften von Manipulationen und Messungen, Teilnehmermerkmalen und ihren funktionalen Beziehungen zur abhängigen Variablen beitragen können.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenMitverantwortlich(e)Dr. Dorothee  Mischkowski"
    },
    {
      "project_id": "546292646",
      "url": "https://gepris.dfg.de/gepris/projekt/546292646",
      "title": "Bewältigung der Replikationskrise in der Machine Learning Modellierung",
      "investigators": "Dr. Kristin  Jankowsky;Professor Dr. Ulrich  Schroeders",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2024",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 546292646",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Machine Learning (ML) Modelle erfreuen sich in vielen wissenschaftlichen Disziplinen wie Medizin, Epidemiologie und Psychologie zunehmender Beliebtheit. Allerdings ist die Übertragung komplexer, statistischer Methoden auf andere Anwendungsgebiete außerhalb ihres Kerngebiets fehleranfällig. So beruhten die anfänglich vielversprechenden Ergebnisse leider häufig auf falsch validierten Modellen, die zu überhöhten Vorhersagegüte führten (z.B. bei der Vorhersage des Suizidrisikos). Da methodische Mängel schwerwiegende negative Folgen sowohl für den Einzelnen als auch für die Gesellschaft haben können, warnen einige Forscher bereits vor einer \"neuen\" Replikationskrise in der ML Forschung. Die bisherige Aufarbeitung hat sich weitgehend auf die algorithmischen Aspekte dieser Krise beschränkt und die besonderen Herausforderungen in der psychologischen Forschung, wie unreliable Indikatoren, kleine Stichproben und fehlende Datenpunkte, außer Acht gelassen. Wir schlagen ein Arbeitsmodell vor, das speziell auf die ML-Forschung in der Psychologie zugeschnitten ist und typische Herausforderungen und Fallstricke aufzeigt. Es besteht aus fünf Schritten: (1) Konzeptualisierung, (2) Datenvorverarbeitung, (3) Modelltraining, (4) Modellvalidierung und -evaluation sowie (5) Interpretation und Generalisierbarkeit. Neben den eher technisch-statistischen umfasst dieses Modell auch die konzeptuellen Aspekte, die für eine erfolgreiche Implementierung von ML in der psychologischen Forschung berücksichtigt werden müssen. Im ersten Projekt führen wir ein systematisches Review über die Forschung der letzten 10 Jahre zur prädiktiven Modellierung in verschiedenen psychologischen Teildisziplinen durch, um so einen Überblick über gängige Praktiken in Bezug auf Konzeptualisierung, Datenvorverarbeitung, Modelltraining, -validierung und Generalisierbarkeit sowie Open-Science-Praktiken zu geben. Im zweiten Projekt werden auf Basis des Reviews typische Fallstricke identifiziert und eine Checkliste entwickelt, die Autor:innen bei der Navigation durch den ML-Workflow unterstützen soll. Zusätzlich wird ein „Risk of bias“ Instrument entwickelt, das zur Beurteilung der Qualität von ML-Studien verwendet werden kann (z.B. bei Meta-Analysen). Im dritten Projekt sollen mittels einer ML Prediction Challenge die Checkliste und die Empfehlungen zur Modellierung experimentell validiert werden. Einer Gruppe werden über die Aufgabenbeschreibung hinaus keine weiteren Informationen gegeben, während die andere Gruppe Empfehlungen erhält, wie sie methodische Fallstricke erkennen und vermeiden können. Zentral ist die Frage, ob die Umsetzung der Empfehlungen zu robusteren, transparenteren und reproduzierbaren Vorhersagen führt. Im vierten Projekt wird ein frei zugänglicher Online-Lernkurs entwickelt, der die Logik und Techniken der ML-Modellierung anschaulich vermittelt. Alle vier Projekte werden Werkzeuge und Ressourcen bereitstellen, um die Replikationskrise in der ML-Modellierung zu entschärfen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464546557",
      "url": "https://gepris.dfg.de/gepris/projekt/464546557",
      "title": "Der Beitrag von Theorie zur (Lösung der) Reliabilitätskrise",
      "subject_area": "Empirische SozialforschungPolitikwissenschaftSoziologische Theorie",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464546557",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Die Reliabilität eines bestimmten empirischen Tests hängt unmittelbar von der Qualität der Theorien ab, auf deren Argumenten der Test basiert. Zu viele unbekannte Faktoren oder konkurrierende kausale Pfade von der Testvariable X zur Ergebnisvariable Y führen dazu, dass die Ergebnisse nicht reliabel sind. Wenn Hypothesentests unter theoretischen Ambiguitäten wiederholt werden, sind möglicherweise ganze Forschungsgebiete bzw. deren Ergebnisse unzuverlässig. Dies könnte den Mangel an Konsens in den erklären bzw. warum Ergebnisse aus diesen Bereichen wenig reproduzierbar sind. Aufgrund der Komplexität menschlicher Interaktion und gesellschaftlicher Organisation ist die theoretische Ambiguität besonders in den Verhaltens- und Sozialwissenschaften prävalent.Ziel des Projektvorhabens ist, die mögliche Rolle von Theorien in der Reproduzierbarkeitskrise zu untersuchen. Es sollen folgende Fragen beantwortet bzw. Ziele verfolgt werden:1\tWie groß ist das Ausmaß theoretischer Ambiguitäten in einem Forschungsgebiet?2\tKönnen computer-gestützte Vergleiche von Kausalmodellen die Ursachen der fehlenden Reliabilität der Ergebnisse aus diesem Feld identifizieren?3\tKann die Reliabilität und Reproduzierbarkeit von Ergebnissen in diesem Feld durch das Crowdsourcen von theoretischen Argumenten verbessert werden?4\tKann eine Computeranwendung dieses Verfahren verbessern und effizienter gestalten, so dass dies in anderen Bereichen der Kognitions-, Verhaltens- und Sozialwissenschaft Anwendung findet?Die ersten beiden Punkte zielen auf eine Frage ab, die im Rahmen des META-REP SPP gestellt wird: Warum variieren Replikationsraten? Die letzten beiden Punkte adressieren die Frage: Wie können Replikationsraten erhöht werden? Im Projektantrag wird argumentiert, dass Replikation und Reliabilität im wissenschaftlichen Forschungsprozess eng miteinander verbunden sind. Adressiert man also Probleme bei der Reliabilität, sollte dies positive Auswirkungen auf die Replizierbarkeit haben. Das vorgeschlagene Verfahren wird in dem Spezialgebiet des Antragstellers – Einwanderung und Umverteilungspräferenzen aus makro-vergleichender Perspektive – getestet. Dieses Feld eignet sich besonders, um zu untersuchen, welche Rolle Theorien spielen bei der fehlenden Reliabilität der Ergebnisse und Replikationen, da es besonders „unzuverlässig“ ist (widersprüchliche Ergebnisse) und sich hauptsächlich auf öffentlich zugängliche Datenquellen stützt. Anhand dieses Testfelds wird eine Computeranwendung entwickelt, die es ermöglicht, die Vergleichsergebnisse kausaler Modelle zu analysieren, zu speichern und öffentlich zugänglich zu machen. Die Ergebnisse und Erfahrungen aus diesem Spezialgebiet sollen in einer Weiterentwicklung der Anwendung einfließen, so dass das vorgeschlagene Verfahren der Kausalmodellvergleiche auf andere Bereiche der Kognitions-, Verhaltens- und Sozialwissenschaften übertragen werden kann.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugUSAMitverantwortlichProfessor Dr. Andreas  BreiterKooperationspartnerProfessor Dr. Jeremy  Freese"
    },
    {
      "project_id": "464313518",
      "url": "https://gepris.dfg.de/gepris/projekt/464313518",
      "title": "Die Reproduzierbarkeit und Robustheit von Sekundäranalysen in der Bildungsforschung: Die Rolle von Publication Bias und Datenanalyseentscheidungen",
      "subject_area": "Entwicklungspsychologie und Pädagogische PsychologieAllgemeines und fachbezogenes Lehren und Lernen",
      "funding_period": "Förderung von 2021 bis 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464313518",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "In den letzten Jahren ist die Robustheit zentraler Befunde der Psychologie, der Sozialwissenschaften, der Medizin und verwandten Disziplinen zunehmend in Frage gestellt worden. Ein Grund, der für mangelnde Replizierbarkeit von Studien aufgeführt wird, sind Freiheitsgrade bei Datenaufbereitungs- und Datenanalyseentscheidungen („researcher degrees of freedom“; Simmons, Nelson & Simonsohn, 2011, S. 1359). Darüber hinaus treffen Forschende nicht nur Entscheidungen über die Auswertung einer Studie, sondern auch darüber, ob und in welcher Form die Ergebnisse publiziert werden. Ein typischer Befund ist, dass Nullbefunde seltener veröffentlicht werden (Publication Bias; Rosenthal, 1979).Ziel unseres Projekts ist die Untersuchung der Robustheit von Befunden in der sekundäranalytischen empirischen Bildungsforschung. Wir untersuchen drei Quellen von möglicher Heterogenität publizierter Studienergebnisse: Entscheidungen der Forschenden (a) für einen bestimmten Datensatz, (b) für eine Datenanalysestrategie und (c) für oder gegen das Verfassen eines Manuskripts zur Studie inklusive der Auswahl einer Publikationsform und der (potenziell selektiven) Auswahl von Befunden für die Veröffentlichung. Als Datengrundlage zur Untersuchung des Publikationsprozesses nutzen wir Datennutzungsanträge, die am Forschungsdatenzentrum des Instituts zur Qualitätsentwicklung im Bildungswesen (FDZ am IQB) gestellt wurden. In den Datennutzungsanträgen beschreiben Forschende, die Daten für eine sekundäranalytische Studie beantragen, ihre Forschungsfragen und Hypothesen sowie ihre Datenanalysestrategie. Wir planen, rund 570 Datenanträge von über 900 Forschenden sowie rund 164 dazugehörige Publikationen zu analysieren, um einen Index für Publication Bias in der empirischen Bildungsforschung zu entwickeln (Ziel A1). Durch den Vergleich der in den Nutzungsanträgen beschriebenen Forschungsfragen mit dem Vorgehen in der späteren Publikation werden wir darüber hinaus Einblicke in die Prävalenz des selektiven Berichtens von Studienergebnissen erhalten (Ziel A2). Im nächsten Schritt führen wir selbst Sekundäranalysen auf Basis der beantragten Datensätze durch. Zunächst soll, auf gleicher Datenbasis und mit der gleichen Analysestrategie, die Reproduzierbarkeit einer ausgewählten Teilstichprobe von aus den Datennutzungsanträgen entstandenen Publikationsergebnissen geprüft werden (Ziel B1). Zweitens soll untersucht werden, wie sich die Entscheidung der Forschenden für eine bestimmte Analysestrategie und einen bestimmten Datensatz auf die Studienergebnisse auswirkt (Ziel B2). Zu diesem Zweck kombinieren wir die Methoden der Integrativen Datenanalyse (IDA) und der Specification Curve Analyse. Insgesamt trägt das Projekt dazu bei, Einblicke in verschiedene Einflussfaktoren der Reproduzierbarkeit und Robustheit von Befunden sekundäranalytischer Bildungsforschung zu gewinnen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "546243727",
      "url": "https://gepris.dfg.de/gepris/projekt/546243727",
      "title": "Ein gründlicher Bayes'scher Workflow zur Untersuchung robuster individueller Unterschiede in der Kognitionswissenschaft",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieAllgemeine und Vergleichende Sprachwissenschaft, Experimentelle Linguistik, Typologie, Außereuropäische SprachenPersönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2024",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 546243727",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Während sich KognitionswissenschaftlerInnen in der Vergangenheit auf experimentelle Effekte konzentriert haben, sind in letzter Zeit auch individuelle Unterschiede in den Blickpunkt des Interesses gerückt. Es ist jedoch unklar, ob kognitive Experimente geeignete Instrumente sind, um individuelle Unterschiede zuverlässig zu erfassen. Und wenn ForscherInnen die Reliabilität ihrer Aufgaben besser verstehen oder gar verbessern wollen, stehen sie vor vielen Hindernissen. So ist es beispielsweise nicht trivial, psychometrische Modelle, die gängigen Reliabilitätsmaßen zugrunde liegen, in Modelle zu übersetzen, die für kognitive Aufgaben geeignet sind. Außerdem mag es zwar einfach erscheinen, mit Hilfe der Power-Analyse zu ermitteln, wie viele Versuchspersonen für eine robuste Schätzung von Korrelationen erforderlich sind, doch ist es wesentlich komplizierter, auch zu planen, wie viele Beobachtungen pro Teilnehmende erforderlich sind. Mit diesem Projekt wollen wir einen prinzipiellen Bayes'schen Arbeitsablauf zur Untersuchung individueller Unterschiede in der Kognitionswissenschaft bereitstellen. Zunächst werden wir ein Werkzeug entwickeln, um Bayes'sche statistische Modelle individueller Unterschiede zu konzipieren. Zweitens werden wir ein Bayes'sches Studienplanungswerkzeug erarbeiten, das es uns ermöglicht, die Anzahl der Beobachtungen und Teilnehmenden im Voraus zu planen, aber auch die Stichprobengröße während der Datenerhebung kontinuierlich anzupassen. Darüber hinaus werden wir eine empirische Studie durchführen, um die Vereinbarungsattraktion in antezedent-reflexiven Konstruktionen besser zu verstehen und die entwickelten statistischen Instrumente anzuwenden und zu validieren.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenMitverantwortlicheProfessorin Audrey  Bürki, Ph.D.;Professor Dr. Shravan  Vasishth"
    },
    {
      "project_id": "464104000",
      "url": "https://gepris.dfg.de/gepris/projekt/464104000",
      "title": "Eine umfassende, gemeinschaftliche Untersuchung der Replikabilität und Robustheit von EEG Analysen",
      "subject_area": "Biologische Psychologie und Kognitive NeurowissenschaftenKognitive und systemische Humanneurowissenschaften",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464104000",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Die Elektroenzephalografie (EEG) ist eine verbreitete Methode zur Untersuchung der menschlichen Kognition und anderer psychologischer Phänomene. Trotz ihrer Popularität ist jedoch die Glaubwürdigkeit dieser Methode in jüngster Zeit nicht unumstritten. Skeptische Einwände basieren darauf, dass neuartige Befunde häufig auf kleinen Stichproben beruhen und dass Replikationsstudien zu publizierten Befunden zu selten unternommen werden. Weiterhin besteht bei EEG Analysen häufig die Wahl zwischen vielen alternativen, plausiblen Methoden und Abläufen. Es ist derzeit völlig unbekannt, in welchem Ausmaß unterschiedliche Analyseabläufe zu unterschiedlichen Ergebnissen führen. Ohne eine systematische Untersuchung der Replizierbarkeit und Robustheit von EEG Befunden mit neuen Datensätzen und alternativen Analysen könnte die Glaubwürdigkeit der EEG Forschung insgesamt auf wackligen Beinen stehen. Daher scheint es uns an der Zeit, die methodische Glaubwürdigkeit der EEG Forschung zu untermauern. Zu diesem Zweck haben wir zwei groß angelegte internationale, kollaborative Projekte ins Leben gerufen.#EEGManyLabs wird die Replizierbarkeit einiger der einflussreichsten EEG Studien mit beispielloser statistischer Power untersuchen, was durch die Zusammenlegung der Ressourcen vieler teilnehmender Labore ermöglicht werden soll, wodurch #EEGManyLabs eines der größten Replikationsprojekte in den kognitiven Neurowissenschaften darstellen wird. Die Replikationsstudien werden es weiterhin ermöglichen, eine umfangreiche Bibliothek von Effektstärken aufzustellen, die zur Planung zukünftiger Studien dienen wird. Die in diesem Projekt generierten Daten werden der wissenschaftlichen Gemeinschaft zur Verfügung gestellt werden, wodurch eine der größten öffentlich zugänglichen EEG-Daten Sammlungen entstehen wird, die auch für zukünftige Studien einflussreich sein wird. Schließlich gehen wir davon aus, dass dieses umfassende, multi-zentrische Projekt helfen wird, zu einem Kulturwandel beizutragen – hin zu gemeinschaftlichen Kollaborationsstudien mit hoher statistischer Power.#EEGManyPipelines ist eine internationale Many-Analysts Studie, in der wir allen teilnehmenden EEG-ForscherInnen einen EEG-Datensatz zur Verfügung stellen, den diese mit einem Analyseverfahren ihrer Wahl auswerten sollen. Durch diese Erhebung der verwendeten Verfahren und der damit erzielten Effekte werden wir systematisch die tatsächliche Diversität von EEG Analysen und ihren Einfluss auf die Variabilität der Ergebnisse untersuchen können. Das wird uns ermöglichen, die Robustheit von EEG Befunden über alternative, plausible Analyseverfahren hinweg zu bestimmen, (sub)optimale Verfahren zu identifizieren und einen Beitrag zu leisten für Richtlinien über die Durchführung und Publikation von EEG Befunden.Insgesamt erwarten wir, dass dieses Projekt deutlich die Glaubwürdigkeit von EEG Forschung unterstützen und zu neuen Standards der Durchführung und Publikation von EEG Studien beitragen wird.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464291459",
      "url": "https://gepris.dfg.de/gepris/projekt/464291459",
      "title": "Förderung der proaktiven Replizierbarkeit in der Computational Communication Science durch Vorverlagerung des Aufwands und Automatisierung von Protokollen",
      "subject_area": "Publizistik und Kommunikationswissenschaft",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464291459",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Dieses Projekt entwickelt Lösungen zur Verbesserung der Replizierbarkeit (und Reproduzierbarkeit) im Feld der Computational Communication Science (CCS), setzt diese um und evaluiert sie. Solche Lösungen werden dringend benötigt, da meta-wissenschaftliche Forschung, einschließlich die aus der ersten META-REP-Förderphase, zeigt, dass Kommunikationswissenschaft allgemein und CCS speziell mit einer Reihe von Problemen konfrontiert sind, die sich negativ auf Replizierbarkeit auswirken. Unser aktuelles Projekt zeigt, dass (a) die Unterscheidung zwischen Reproduktion und Replikation in CCS nicht so klar ist wie in anderen Feldern und (b) es eine erhebliche Diskrepanz zwischen den von Forschenden bereitgestellten Materialien und den für Replikationen benötigten Informationen gibt. Beide Probleme sind größtenteils auf die untersuchten Themen, die Methoden und die Daten zurückzuführen, die in CCS üblicherweise verwendet werden. So können Medieninhalte und digitale Spurendaten aus rechtlichen und/oder ethischen Gründen oft nicht weitergegeben werden und gängige Erhebungsmethoden, z.B. für Social Media-Daten, beschränken die Weitergabe von Daten aufgrund der Nutzungsbedingungen der beteiligten Anbieter. Darüber hinaus zeichnet sich CCS durch eine schnelle Entwicklung der untersuchten Themen aus (z.B. öffentlicher Diskurs, Nachrichten oder Plattformnutzung). Frühere Forschungsarbeiten, einschließlich unserer eigenen, verdeutlichen die Bedeutung des Publikations- und Reviewprozesses für Replizierbarkeit/Reproduzierbarkeit. So macht es etwa einen erheblichen Unterschied, ob Fachzeitschriften oder Konferenzen Anforderungen an das Teilen von Daten und anderen Materialien (z.B. Code) an Einreichende stellen. Entsprechend ist das Ziel des für die zweite META-REP-Förderphase vorgeschlagenen Projekts die Entwicklung und Erprobung von Lösungen zur Verbesserung der Replizierbarkeit/Reproduzierbarkeit. Dazu wird das Projekt Replikations-/Reproduktionsprotokolle zur Förderung einer “proaktiven Replizierbarkeit” entwickeln, die Einreichende auffordern sollen, bereits bei der Einreichung Änderungen einzubauen, die nachweislich die Replizierbarkeit/Reproduzierbarkeit einer Arbeit verbessern. Dafür entwickeln wir zunächst Protokolle für die CCS und erarbeiten dann Online-Tools, mit denen die Protokolle halbautomatisch ausgefüllt werden können. Dabei verwenden wir Data Mining und moderne Sprachmodelle (LLM), um die notwendigen Informationen aus den Manuskripten zu extrahieren und Vorschläge zur Verbesserung der Reproduzierbarkeit/Replizierbarkeit einer Studie zusammenzustellen. Die Protokolle und die erstellten Tools werden mit einer Fachzeitschrift und der Fachgruppe unserer wichtigsten internationalen Fachgesellschaft systematisch in zwei experimentellen Studien evaluiert, um Effekte auf die Replizierbarkeit/Reproduzierbarkeit zu bewerten. Schließlich werden die Ergebnisse in Richtlinien und Schulungsmaterialien für die CCS und darüber hinaus zusammengefasst.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "546419617",
      "url": "https://gepris.dfg.de/gepris/projekt/546419617",
      "title": "Grosse Sprachmodelle als Lösungsansatz für die Generalisierbarkeitskrise",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2024",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 546419617",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Das Gebiet der Psychologie kämpft mit einer Krise der Generalisierbarkeit, bei der empirische Erkenntnisse spezifisch für einzelne Aufgabe gelten und sich nicht über Kontexte hinweg replizieren lassen. Traditionelle Lösungen, die eine erhöhte methodologische Strenge betonen, adressieren per se nicht die Herausforderung, die eine grösser werdende Menge von Konstrukten und Messungen zu organisieren, deren Beziehungen zueinander weitgehend unbekannt sind. Eine Neubewertung der Beziehung zwischen Konstrukten und Messungen ist nötig, zusammen mit einem strukturierten Ansatz, der die Umstände antizipiert unter denen eine Generalisierung über Messungen oder Kontexte erfolgreich ist oder nicht. Das vorgelegte Forschungsprogramm legt einen sprachbasierten Ansatz vor, der verspricht, das nomologische Netzwerk aus psychologische Konstrukte und zugehörige Messungen zu messen. Sprache, als Basis für theoretische Formulierungen und Methoden der Datensammlung (z. B. Selbstberichte, experimentelle Instruktionen), kann neuerdings mit Hilfe fortgeschrittener Sprachmodelle genutzt werden, um konzeptuelle und empirische Beziehungen herzustellen. Speziell schlägt das Programm vor, mittels modernen Sprachmodellen die Beziehungen zwischen Konstrukten und zugehörigen Messungen umfassende zu untersuchen. Dieser Ansatz verspricht, die konzeptuelle Überschneidung zwischen theoretischen Konstrukten und deren Operationalisierungen zu klären, sowie die konvergente und divergente Validität bestehender und neuer psychologischer Instrumente zu prognostizieren. Das erwartete Ergebnis ist ein geklärtes nomologisches Netzwerk von Konstrukten und zugehörigen Messungen. Letztendlich ist es das Ziel dieser Forschung das Problem der begrenzten Generalisierbarkeit in der Psychologie anzugehen, um unser Verständnis der Bedingungen zu verbessern, unter denen empirische Phänomene über Messungen und Kontexte hinweg replizieren.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenKooperationspartnerDr. Marcel  Binz"
    },
    {
      "project_id": "464346699",
      "url": "https://gepris.dfg.de/gepris/projekt/464346699",
      "title": "Kognitive Modellierung: Fluch oder Segen für Replizierbarkeit in der Psychologie?",
      "subject_area": "Allgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464346699",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Die wissenschaftliche Psychologie wird gegenwärtig von einer Vertrauenskrise erschüttert, welche davon ausgelöst wurde, dass viele einflussreiche psychologische Studien nicht repliziert werden können. Eine mögliche Erklärung für das Scheitern von Replikationsstudien ist, dass psychologische Theorien oft unterspezifiziert sind. Als mögliche Gegenmaßnahme wurde vorgeschlagen, formale kognitive Modellierung einzusetzen, um so präzisere Vorhersagen zu generieren. Jedoch wurde nie empirisch geklärt, ob kognitiver Modellierung überhaupt für die Replizierbarkeit nützlich ist. Angesichts der großen Anzahl von arbiträren Analyseentscheidungen, die während der kognitiven Modellierung getroffen werden müssen, könnte kognitive Modellierung für die Replizierbarkeit sogar kontraproduktiv sein. In unserem Antrag schlagen wir vor, die Replizierbarkeit von Modellierungen zu untersuchen, die auf der Theorie des Bayesianischen Gehirns basieren, wobei wir auf die Replizierbarkeit von drei exemplarischen Studien fokussieren. Als ersten Schritt möchten wir versuchen, anhand des Originaldatensatzes die Analysen der Originalstudien zu reproduzieren. Als zweiten Schritt möchten wir die Robustheit von kognitiven Modellierungen untersuchen, indem wir systematisch den Einfluss einer Vielzahl theoretisch äquivalenter Analyseentscheidungen auf die Ergebnisse untersuchen. Zu guter Letzt möchten wir in exakten Replikationsstudien überprüfen, ob sich die Ergebnisse der Originalstudien in neuen Studien wiederholen lassen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464369680",
      "url": "https://gepris.dfg.de/gepris/projekt/464369680",
      "title": "Konzeptuelle Replikationen - Richtlinien zur Durchführung und Einflussfaktoren auf die Replizierbarkeit in unterschiedlichen psychologischen Disziplinen",
      "investigators": "Professorin Dr. Anne  Gast;Professorin Dr. Steffi  Pohl;Dr. Marie-Ann  Sengewald;Dr. Mathias  Twardawski",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung von 2021 bis 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464369680",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Um die Ursachen für heterogene Effekte in Replikationen zu verstehen, ist es nötig Untersuchungsbedingungen systematisch zu variieren. Wir behandeln dies in konzeptuellen Replikationen, basierend auf dem causal replication framework (CRF, Steiner & Wong, 2018; Steiner, Wong, & Anglin, 2019). Das CFR nutzt kausaltheoretische Erkenntnisse für die Definition und Konstruktion von Replikationsstudien. Konkret werden die Voraussetzungen definiert unter denen Variationen in den Untersuchungsbedingungen als kausale Ursachen für heterogene Effekte identifiziert werden können. Um Einflussfaktoren auf die Replizierbarkeit systematisch zu untersuchen, werden Design- sowie Analysestrategien entwickelt – bisher am Beispiel von Anwendungen in der Pädagogischen Psychologie. In anderen psychologischen Disziplinen variieren sowohl die Einflussfaktoren als auch die Voraussetzungen zur Konstanthaltung von Replikationsbedingungen und es müssen entsprechende Strategien zur Implementierung des CRF entwickelt werden. Ziel unseres Projektes ist es die Anwendbarkeit des CRF auf verschiedene psychologische Disziplinen auszuweiten. Wir führen konzeptuelle Replikationsstudien in der Sozialpsychologie und der Kognitiven Psychologie durch, die unterschiedliche Herausforderungen für Replikationsstudien beinhalten, und vergleichen diese mit den Anwendungen in der Pädagogischen Psychologie. Darüber hinaus geben wir Kooperationsmöglichkeiten für zusätzliche interdisziplinäre Anwendungen des CRF im Rahmen des SPP an. Somit, behandeln wir die Implementierung des CRF in unterschiedlichen Disziplinen, untersuchen Einflussfaktoren auf die Replizierbarkeit innerhalb und zwischen den Anwendungen und leiten Richtlinien für die Durchführung konzeptueller Replikationen ab.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugUSAKooperationspartnerinnen / KooperationspartnerProfessor Peter  Steiner, Ph.D.;Professorin Vivian  Wong, Ph.D."
    },
    {
      "project_id": "467852570",
      "url": "https://gepris.dfg.de/gepris/projekt/467852570",
      "title": "Koordinationsfonds",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieSozialpsychologie und Arbeits- und Organisationspsychologie",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 467852570",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Meta-wissenschaftliche Forschung zur Replizierbarkeit, Reproduzierbarkeit und Generalisierbarkeit empirischer Erkenntnisse ist – und bleibt – ein \"heißes Thema\" in den Sozial-, Kognitions- und Verhaltenswissenschaften. Neue Zeitschriften für Meta-Wissenschaft wurden ins Leben gerufen; etablierte Zeitschriften widmen Replikationsprojekten \"Sonderausgaben\"; neue wissenschaftliche Gemeinschaften, Institute und Initiativen wurden gegründet; und viele Zeitschriften und Forschungsförderer haben ihre Richtlinien geändert, um die Sichtbarkeit und Relevanz von Replizierbarkeit, Reproduzierbarkeit und Generalisierbarkeit zu erhöhen. Das von der DFG geförderte Schwerpunktprogramm \"META-REP\" (SPP 2317) trägt sichtbar zu diesen Entwicklungen bei, indem es drei übergreifende Fragen mit (meta-)wissenschaftlichen Methoden und Ansätzen angeht: (1) Was meinen wir, wenn wir von \"Replizierbarkeit\" sprechen? (die \"WAS\"-Frage); (2) Warum sind Replikationsraten so niedrig und variabel? (die \"WARUM\"-Frage); und (3) Was können wir tun, um die Replikationsraten zu erhöhen? (die \"WIE\"-Frage). In der ersten Förderphase von META-REP (2021-2024) haben die 15 geförderten Projekte wesentlich dazu beigetragen, diese Fragen zu beantworten, und das Koordinationsprojekt hat aktiv dazu beigetragen, diese Arbeiten zu koordinieren, zu unterstützen und zu fördern, unter anderem durch (1) die Einrichtung von vier Arbeitsgruppen (\"Task Forces\"), die sich mit übergreifenden meta-wissenschaftlichen Fragen befassen, (2) die Finanzierung von Forschung über Projekte hinweg (\"Schatzkistenprojekte\"), (3) die Organisation von Veranstaltungen innerhalb des Programms (Retreats, Vorlesungsreihen, programmspezifische Workshops), (4) die Organisation einer internationalen Meta-Science-Konferenz im Jahr 2024, (5) die Bereitstellung von IT-Dienstleistungen für die Projekte, (6) die Zusammenarbeit mit meta-wissenschaftlichen Initiativen über META-REP hinaus und (7) die Durchführung eigener meta-wissenschaftlicher Forschung. Das Koordinationsprojekt plant, diese Aktivitäten in der zweiten Förderphase fortzusetzen und zu intensivieren. Konkret streben wir an, META-REP noch sichtbarer in der internationalen (meta-)wissenschaftlichen Gemeinschaft zu machen, die Zusammenarbeit mit Partnern auf der ganzen Welt zu stärken und Plattformen für den wissenschaftlichen Austausch über Meta-Wissenschaft in den Sozial-, Kognitions- und Verhaltenswissenschaften bereitzustellen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464552782",
      "url": "https://gepris.dfg.de/gepris/projekt/464552782",
      "title": "METEOR 2.0 – Meisterung expertenwissensbasierter Robustheitsanalysen in den kognitiven Neurowissenschaften",
      "investigators": "Professor Dr. Stefan  Debener;Dr. Carsten  Gießing;Professorin Dr. Andrea  Hildebrandt;Professorin Dr. Christiane M.  Thiel",
      "subject_area": "Biologische Psychologie und Kognitive NeurowissenschaftenPersönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464552782",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Eine entscheidende Voraussetzung für die Replizierbarkeit von Hirn-Kognitions-Assoziationen, die im Labor oder außerhalb mit stationären und mobilen Neuroimaging-Methoden erfasst werden, ist die Rangordnungsstabilität neuronaler Parameter, die aus verrauschten und komplexen Signalaufzeichnungen mit unterschiedlichen Analyseverfahren abgeleitet werden. Angesichts der Komplexität von Neuroimaging-Daten ist in den kognitiven Neurowissenschaften eine sehr große Zahl potenzieller Analysepipelines denkbar. Robustheit ist eine entscheidende Voraussetzung für die Replikation mit unterschiedlichen Daten und unterschiedlichen Analysepipelines. Eine Robustheitsanalyse kann jedoch nur mit umfassender Kenntnis der möglichen Datenanalyseoptionen entworfen werden. In METEOR 1.0 haben wir argumentiert, dass der Wissensraum der analytischen Möglichkeiten für einzelne Wissenschaftler*innen sehr überschaubar ist. Um dieses Problem zu entschärfen und die Robustheit von Ergebnissen von mobilen EEG und graphen-theoriebasierten fMRT Analysen zu verbessern, haben wir in METEOR 1.0 einen Wissensraum analytischer Entscheidungen für zwei bildgebende Modalitäten erstellt, die besonders von verrauschten und komplexen Datenstrukturen betroffen sind. Wir haben auch Lösungen entwickelt, die auf maschinellem Lernen basieren, um mit der überwältigenden Anzahl möglicher Analyseoptionen umzugehen. In METEOR 2.0 planen wir, die bisher entwickelten Analysemethoden und -werkzeuge zu optimieren, indem wir auch ihre Nachhaltigkeit sicherstellen und sie auf Plausibilität, Machbarkeit, Akzeptanz, sowie ihre positive und potenziell unerwünschte Nutzung testen. Insbesondere planen wir, die Aktualisierung der generierten Wissensräume zu automatisieren, die Multiverse-Analysemethoden zu erweitern, und eine modulare, vielseitig einsetzbare METEOR-Toolbox zu programmieren. Die Toolbox wird es ermöglichen, 1) das Multiversum auf der Basis eines umfassenden, von Experten evaluierten Wissensraums zu definieren, 2) das Multiversum auf der Basis von Erkenntnissen aus Sensitivitätsanalysen einzuschränken, 3) Robustheitsanalysen mit Hilfe von maschinellem Lernen durchzuführen und 4) die Variabilität der Ergebnisse zu visualisieren und/oder die Ergebnisse über Analyseoptionen hinweg zu integrieren. Wir werden zudem an der Standardisierung von Studienprotokollen arbeiten und ihre Verbreitung fördern. All diese Arbeiten sollten zu einer robusteren kognitiven Neurowissenschaft beitragen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464590891",
      "url": "https://gepris.dfg.de/gepris/projekt/464590891",
      "title": "Modelle, Maße, Moderatoren - Exploration und Erklärung von Heterogenität in psychologischen Replikationen",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464590891",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Seit dem Beginn der Replikationskrise wird die Heterogenität von Effektgrößen als eine mögliche Ursache für geringe Replizierbarkeit diskutiert. Allerdings weisen die meisten Meta-Meta-Studien zu dieser Heterogenität methodische Mängel auf. Insbesondere verwenden sie häufig standardisierte Effektgrößen oder setzen das Ausmaß an Heterogenität nicht mit der Größe des Effekts in Beziehung. Beide Praktiken haben, wie wir in der ersten Förderphase von META-REP zeigen konnten, negative Auswirkungen auf die Genauigkeit und Interpretierbarkeit von Heterogenitätsschätzungen. Wir schlagen daher vor, Heterogenität mittels eines alternativen Maßes zu bewerten, nämlich mittels des Variationskoeffizienten der unstandardisierten Effekte. Durch die Verwendung dieses Maßes konnten wir, im Gegensatz zu früheren Meta-Meta-Studien, eine erhebliche und theoretisch relevante Heterogenität sogar in direkten Replikationen psychologischer Effekte feststellen. Aufbauend auf diesen Erkenntnissen werden wir in der zweiten Förderphase von META-REP drei Ziele verfolgen: Wir wollen, erstens, die Messung von Heterogenität in Replikationen verbessern und die Interpretierbarkeit der entsprechenden Ergebnisse erhöhen. Wir streben, zweitens, an, das empirische Wissen über Heterogenität in psychologischen Replikationen zu erweitern. Schließlich ist unser drittes Ziel, Heterogenität zu erklären, indem wir sie auf identifizierte Variablen zurückführen. Konkret schlagen wir vier Module vor, um diese Ziele zu erreichen: Modul 1: In Simulationen entwickeln wir datengenerierende Modelle, die die Entstehung von Heterogenität in Effektgrößen präzise beschreiben. Zur Messung der Heterogenität werden dann sowohl Standard-Indizes als auch der Variationskoeffizient verwendet, um mögliche Verzerrungen in Heterogenitätsschätzungen zu untersuchen und die relative statistische Performanz der Verfahren zu vergleichen. Modul 2: Anhand empirischer Daten aus konzeptuellen Replikationen wollen wir Heterogenität über mehrere experimentelle Kontextfaktoren hinweg betrachten. Wir vergleichen Heterogenität a) über verschiedene Arten von Effekten, b) über verschiedene Operationalisierungen der gleichen Manipulation und c) unter Berücksichtigung möglicher Moderatoren. Modul 3: In den Modulen 1 und 2 beschränken wir uns auf Vergleiche zwischen identischen Messvariablen. In Meta-Analysen werden jedoch in der Regel mehrere verschiedene Messgrößen zusammengefasst. Daher erweitern wir das Simulationsschema und die empirische Datenbasis, um solche Variation untersuchen zu können. Modul 4: In der ersten Förderphase dieses Projekts haben wir die Softwareumgebung \"MetaPipeX\" entwickelt, um metaanalytische Inferenzen zu vereinheitlichen und ein Repositorium mit standardisierten, offenen Daten aufzubauen. Basierend auf den Modulen 1-3 erweitern wir MetaPipeX, um konzeptionelle Replikationen, Moderatorenanalysen und ähnliche Elemente zu integrieren und die in den Modulen 1-3 verwendeten Daten einzubeziehen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugGroßbritannien, NiederlandeKooperationspartnerDr. Johannes  Hönekopp;Professor Dr. Jelte  WichertsEhemaliger AntragstellerDr. Frank  Renkewitz, bis 6/2025"
    },
    {
      "project_id": "464507200",
      "url": "https://gepris.dfg.de/gepris/projekt/464507200",
      "title": "Reproduzierbarkeit und Robustheit sozialwissenschaftlicher Forschung mit Beobachtungsdaten: Ausmaß, Bedingungsfaktoren und Maßnahmen zur Verbesserung",
      "investigators": "Professorin Dr. Katrin  Auspurg;Professor Dr. Josef  Brüderl",
      "subject_area": "Empirische Sozialforschung",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464507200",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Das Projekt führt Analysen zur Reproduzierbarkeit und Robustheit von Artikeln durch, welche dieselben „large-N“ Beobachtungsdaten verwenden (European Social Survey). Die Artikel unterscheiden sich aber in Disziplinen, Zeitschriften, Autor:innenkonstellationen und anderen Faktoren, die vermutlich mit unterschiedlich hohen Reproduktionsraten zusammenhängen. Unser Projekt geht in vier Schritten vor: Während der ersten Projektphase haben wir (A) die Zugänglichkeit von Replikationsmaterialien für etwa 1.200 Artikel in einem „openess audit“ geprüft (Anfrage bei Autoren nach der Verfügbarkeit von Daten sowie Analysecode). Anschließend haben wir (B) bei einer zufälligen Teilmenge von 100 Artikeln Analysen zur Reproduzierbarkeit durchgeführt (lassen sich die Ergebnisse der Autoren reproduzieren, wenn man ihren Code auf ihre Daten anwendet). Für die zweite Projektphase planen wir, © für diese Artikel „Korrektheits-/Kongruenzprüfungen“ durchzuführen (Abwesenheit von Kodierfehlern, „Kongruenz“ zwischen dem, was in den Artikeln berichtet und mit dem Analysecode tatsächlich durchgeführt wird). Im letzten Schritt widmen wir uns (D) Robustheitsanalysen (bleiben die Ergebnisse bei scheinbar marginalen Änderungen von Datenaufbereitungen oder -analysen stabil, wie etwa Änderungen der Gewichtung, Imputation oder Outlier-Behandlung). Mit diesen vier Schritten streben wir ein umfassendes Audit möglicher Bedrohungen transparenter und glaubhafter Forschung an. Im Gegensatz zu bestehenden Audits berücksichtigen wir Publikationen sowohl mit hohem als auch niedrigem Impact. Zudem ermöglicht unser Audit Vergleiche zwischen Disziplinen mit unterschiedlich starker Umsetzung der „FAIR-Prinzipien“ (findable, accessible, interoperable, reusable materials). Auf diese Weise können Forschungsbereiche identifiziert werden, bei denen Maßnahmen zur Verbesserung besonders angebracht und effektiv erscheinen. Die drei eng miteinander verbundenen, übergreifenden Forschungsziele für die zweite Projektphase sind: (1) Abschluss von Arbeiten zur Analyse des Ausmaßes reproduzierbarer und robuster Ergebnisse auf den vier Stufen unseres Audits (als Beitrag zur META-REP „What“ Frage); (2) Analyse von Bedingungen für unterschiedliche Reproduzierbarkeit und Robustheit, wozu Merkmale auf Artikel-, Autoren- und Zeitschriftenebene analysiert werden (als Beitrag zur META-REP „Why“ Frage); und (3) Entwicklung einfach implementierbarer Maßnahmen (wie z.B. Computer-Code), mit denen sich Reproduzierbarkeit und Robustheit verbessern lassen (als Beitrag zur META-REP „How“ Frage).DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464446725",
      "url": "https://gepris.dfg.de/gepris/projekt/464446725",
      "title": "Reproduzierbarkeit und Robustheit von Instrumentvariablen und Randomized Controlled Trials in den Wirtschaftswissenschaften",
      "subject_area": "Wirtschaftspolitik, Angewandte Volkswirtschaftslehre",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464446725",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Dieses Projekt untersucht Reproduzierbarkeitsraten in verschiedenen wirtschaftswissenschaftlichen Literatursträngen. Dabei werden wir einen \"Replikationsmarkt\" sowie Reproduktionen und zusätzliche Robustheitstests unter Verwendung der Originaldaten verwenden (im Folgenden R&R-Replikationen). Forschungsziele sind erstens, eine Definition von \"Reproduzierbarkeit\" für R&R-Replikationen zu erarbeiten (das \"What\") und, zweitens, Gründe für unterschiedliche Reproduzierbarkeitsraten und Marktprognosen zu ermitteln (das \"Warum\").Für die \"Was\"-Frage, ist die Definition der \"Reproduzierbarkeit\" für R&R-Replikationen ein wichtiger und innovativer erster Schritt. In den Wirtschaftswissenschaften spielen R&R-Replikationen von Originaldatensätzen eine wichtige Rolle für das Verständnis der Reproduzierbarkeit, da nur ein kleiner Teil der empirischen Literatur aus standardisierten Laborsettings stammt. Direkte Replikationen sind selten und teuer. Daher ist die Erfolgsdefinition von R&R-Replikationen von zentraler Bedeutung, um die Reproduzierbarkeit zu verbessern. Hier werden wir eigene Erfahrungen mit ähnlichen R&R-Replikationsstudien nutzen, aber auch frühere R&R-Replikationen hinzuziehen und eine Befragung unter Replikations-Forscherinnen durchführen.Für die Frage nach dem \"Warum\" (dem “Why”), werden wir 30 Papiere zu ähnlichen Themen in führenden Zeitschriften replizieren, 15 mit Instrumentvariablen (IV) und 15 mit Randomized Controlled Trials (RCTs). Dies sind die beiden wichtigsten Methoden für kausale Inferenz in der angewandten Wirtschaftswissenschaft. Wir vermuten, dass beide mit unterschiedlichen Wahrscheinlichkeiten in R&R Replikationen reproduzierbar sind, da IVs anfälliger für p-Hacking und Publication Bias sind. Diese werden wir auch im Replikationsmarkt testen. Das Hauptproblem von IVs, ist die faktisch fehlende Vorspezifizierung der Analyse. Wir erwarten bei einer R&R-Replikation, dass IV-basierte Papiere niedrigere Replikationsraten aufweisen als RCTs, da p-Hacking aufgedeckt werden kann. RCTs hingegen werden oft in spezifischen Stichproben durchgeführt, was in R&R-Replikationen nicht aufgedeckt werden kann. Um die Verallgemeinerbarkeit über Kontexte hinweg zu beurteilen, werden wir daher in einer ExpertInnenbefragung einen Crowdsourcing-Ansatz wie das Bayesian Truth Serum verwenden. Die 30 R&R-Replikationen werden wir als Anreiz für den Replikationsmarkt verwenden, den wir für 60 Studien aus der gleichen Literatur unter ExpertInnen durchführen, um informierte Vorhersagen zur Reproduzierbarkeit zu erhalten. Wir nutzen diesen Markt und dadurch das Fachwissen von ForscherInnen, um unser Verständnis der \"Warum\"-Frage in Bezug auf p-Hacking, Publication Bias, Spezifikationsrobustheit und zu geringe Stichprobengrößen zu vertiefen.Ein Merkmal der Verbreitungsphase des Projekts wird die Interaktion mit PraktikerInnen und der breiteren Öffentlichkeit über die Glaubwürdigkeit der Forschung an der Schnittstelle zwischen Wissenschaft und Politik sein.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugSchweden, USAKooperationspartnerinnen / KooperationspartnerProfessorin Anna  Dreber Almenberg, Ph.D.;Professor Dr. Nathan  Fiala;Professor Dr. Magnus  Johannesson"
    },
    {
      "project_id": "464488178",
      "url": "https://gepris.dfg.de/gepris/projekt/464488178",
      "title": "Standardisierung psychologischer Forschungsmethoden als Determinante von Replizierbarkeit",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, MethodenAllgemeine, Kognitive und Mathematische Psychologie",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464488178",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Globale, offene Standards, wie die feste Breite des Fußballtors, verringern Konflikte, wenn Spieler aus der ganzen Welt zusammenkommen. Der Psychologie mangelt es an solchen Standards—und es ist kein Zufall, dass \"die Torpfosten verschieben\" oft als Metapher bemüht wird, wenn Replikationsversuche fehlschlagen und eine Debatte entbrennt. Gleichzeitig sind über die Sozial- und Verhaltenswissenschaften hinweg Schwierigkeiten bei der Replikation empirischer Arbeiten dokumentiert worden, das heißt die Reproduktion von Analysen auf der Grundlage derselben Daten, und die Replikation mit neuen Daten schlagen oft fehl. Während sich die Psychologie mit dieser Krise auseinandersetzt, fragen viele, was eine direkte Replikation ausmacht — wann sind Materialien und Methoden ausreichend ähnlich um als gleich zu gelten? Finden wir einen Effekt mit einem Maß, aber nicht mit einer Variante desselben kann uns das Aufschluss über Generalisierbarkeit geben und die Theorie vorantreiben. Wenn aber Forscher Freiheitsgrade bei der Messung ausnutzen, um das gewünschte Ergebnis herbeizuführen, jagen wir falschen Fährten nach. Globale, offene Standards schränken Freiheitsgrade ein und zeigen auf transparente Weise eine Einigkeit über grundlegende Forschungsaspekte auf: Einheiten, Normen und Messverfahren. Ohne Standards enden die Bemühungen zum Aufbau einer kumulativen Evidenzbasis durch Replikation und Meta-Analyse oft in Gezeter über die Torpfosten. Mit Standards wird die Planung, die Beurteilung der Reproduzierbarkeit früherer Forschung und die Synthese von Evidenz einfacher.Wir planen ein umfassendes Forschungsprogramm um die Rolle von Standardisierung in der Reproduzierbarkeit, Robustheit, Replizierbarkeit und Generalisierbarkeit psychologischer Forschung zu verstehen. Wir untersuchen, wie offene Standards beschleunigen können, dass die Psychologie als kumulative Wissenschaft reift. Dazu entwickeln wir SOBER, eine Methode um Standardisierung von Messinstrumenten mit einem maschinenlesbaren Metadatenstandard zu beschreiben und zu quantifizieren. Wir überprüfen die Nützlichkeit von SOBER, indem wir den Zusammenhang von globalen Standards mit Replizierbarkeit in existierenden Meta-Analysen und großangelegten Replikationsprojekten überprüfen. Wir katalogisieren flexible Forschungspraktiken, simulieren ihre Kosten für psychometrische Qualität und Robustheit von Evidenz und testen diese Simulationen in einer Reihe von Studien in denen bekannte psychologische Messverfahren experimentell variiert werden. Wir integrieren diese Befunde in einem Framework, um die Auswirkungen von ad-hoc Modifikationen auf Meta-Analysen zu beurteilen. Wir wollen einen Kulturwandel in der Psychologie in Richtung Standardisierung vorantreiben, indem wir Werkzeuge und Lehr-/Lernmaterial entwickeln, sowie Debatten anstoßen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugGroßbritannien, Niederlande, SchweizKooperationspartnerinnen / KooperationspartnerProfessorin Dr. Lisa M.  DeBruine;Professor Dr. Renato  Frey;Professor Dr. Daniël  LakensEhemaliger AntragstellerProfessor Dr. Malte  Elson, bis 8/2023"
    },
    {
      "project_id": "546323839",
      "url": "https://gepris.dfg.de/gepris/projekt/546323839",
      "title": "SYNTH: Evaluation von Transformermodellen für synthetische Replikationen, nomologische Netze und Peer Reviews",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2024",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 546323839",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Die wissenschaftliche Reformbewegung hat Methoden identifiziert und umgesetzt, um die Robustheit, Zuverlässigkeit und Replizierbarkeit von Forschung zu verbessern. Diese Methoden sind jedoch arbeitsintensiv, und ihre Anwendung wird nicht durchgängig belohnt. Forscher werden beispielsweise ermutigt, ihre Projekte zu präregistrieren, d.h. Design, Hypothesen und Analyseplan vor der Datenerhebung festzulegen. Peer Reviewer sollen überprüfen, ob Abweichungen von diesen Protokollen transparent berichtet werden. Leider lesen Reviewer Präregistrierungen aus Zeitgründen nur selten, wenn sie ein Manuskript beurteilen. Dies gefährdet deren erhofften Nutzen. Jüngste Fortschritte im Bereich großer Sprachmodelle (Large Language Models, LLMs) haben das Potenzial, die Kosten für Aufgaben, die von der wissenschaftlichen Gemeinschaft vernachlässigt wurden, zu reduzieren. SYNTH zielt darauf ab, die Qualität von Forschung zu erhöhen, indem Werkzeuge entwickelt werden, die Forscher in drei Kernbereichen unterstützen: (1) Synthetische Replikationen nutzen ein spezialisiertes LLM, um die Antwortmuster von Umfrageteilnehmern bei Fragebögen (z.B. Persönlichkeitstests) vorherzusagen. Mit diesen synthetischen Daten können Reviewer potenzielle Replikationsprobleme bei neu entwickelten Fragebögen erkennen, bevor empirische Daten gesammelt werden. Im Rahmen des Programms wird eine große Auswahl bestehender Instrumente synthetisch repliziert und empirisch neu untersucht, falls das LLM mögliche Probleme identifiziert. (2) Das Synthetische Nomologische Netz ist eine LLM-basierte semantische Suchmaschine, die Tausende von Instrumenten in den Verhaltenswissenschaften kartiert. Da viele veröffentlichte Instrumente dasselbe Konzept messen, kann die Suchmaschine genutzt werden, um potenzielle Redundanzen zu identifizieren. Ebenso dient das Synthetische Nomologische Netz als Werkzeug für Forscher, indem es ihnen proaktiv ermöglicht, die Existenz eines vorhandenen Maßes im Feld zu überprüfen und so unnötige Duplikation zu vermeiden. (3) Der Synthetische Peer ist ein speziell geschultes LLM, das Präregistrierungen mit Manuskripten abgleicht und Abweichungen vom ursprünglichen Protokoll hervorhebt, um Reviewer bei ihrer Arbeit zu unterstützen. In Zusammenarbeit mit der Zeitschrift Psychological Science führt SYNTH eine Feldstudie durch, um die Wirksamkeit des Synthetischen Peers zu bewerten. Neben der Entwicklung und Evaluation dieser neuartigen Anwendungen für LLMs in der Forschung wird SYNTH auch zeigen, wie die Forschungsgemeinschaft die Risiken von LLM-Nutzung abwägen und auf eine solide ethische Grundlage stellen kann. Das Programm betont Einvernehmlichkeit, Privatsphäre, Fairness und Transparenz und verwendet LLMs nur zur Priorisierung, Entscheidungen werden stets von Menschen getroffen (oft als ethische künstliche Intelligenz bezeichnet). In SYNTH überwachen wir sorgfältig Fairness, mögliche Biases und deren Auswirkungen auf die Wissenschaft als Ganzes durch unser Vorhaben.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugAustralien, SchweizPartnerorganisationSchweizerischer Nationalfonds (SNF)Kooperationspartnerinnen / KooperationspartnerProfessor Dr. Malte  Elson;Dr. Juri  Opitz;Professorin Dr. Simine  Vazire"
    },
    {
      "project_id": "464350745",
      "url": "https://gepris.dfg.de/gepris/projekt/464350745",
      "title": "Systematisieren der Theoriebildung",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologieEntwicklungspsychologie und Pädagogische PsychologiePersönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464350745",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Theoriebildung und Reproduzierbarkeit haben eine bidirektionalen Verbindung: Forscher Theorien unterschiedlich interpretieren und folglich testen, erwarten wir eine geringe Reproduzierbarkeit. Gleichzeitig ist aufgrund der geringen Reproduzierbarkeit unklar, welche Erkenntnisse durch eine Theorie erklärt oder in diese einbezogen werden müssen. Anhand der Fallstudie zur Leseforschung und Legasthenieforschung wollen wir herausfinden, wie dieser Teufelskreis durchbrochen werden kann. In Arbeitspaket 1 werden wir systematisch die notwendigen Schritte für eine fundierte Theoriebildung skizzieren und dabei Kausaltheorien aus der Lese- und Entwicklungs-Legasthenieforschung beschreiben. Wir werden eine Vorlage erstellen, die auf verallgemeinerbaren Schritten im Theoriebildungsprozess basiert. In Arbeitspaket 2 konzentrieren wir uns auf ein spezifisches Werkzeug, das zur Verbesserung der Theoriebildung und damit der Reproduzierbarkeit vorgeschlagen wurde: Computermodellierung. Wir werden die Gründe untersuchen, warum Computermodelle die Reproduzierbarkeit verbessern können, und angeben, in welchen Fällen Computermodellierung bei der Theoriebildung besonders nützlich sein kann. In Arbeitspaket 3 konzentrieren wir uns auf die Umsetzung der Ergebnisse der Arbeitspakete 1 und 2. Wir werden ein lebendiges Dokument erstellen, damit die Ergebnisse und Empfehlungen des aktuellen Projekts für Forscher weltweit leicht zugänglich sind. Wir werden auch darüber diskutieren, ob es fruchtbar sein wird, einige unserer Empfehlungen vorzuschreiben. Zusammengefasst zielt das Projekt darauf ab, sich auf eine Fallstudie zu konzentrieren, die Ergebnisse jedoch auf andere Bereiche der Sozial- und Verhaltenswissenschaften zu übertragen, mit dem Ziel, den Teufelskreis zwischen vagen Theorien und geringer Reproduzierbarkeit zu durchbrechen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenMitverantwortlicheProfessor Dr. Benjamin  Gagl;Professor Dr. Gerd  Schulte-Körne"
    },
    {
      "project_id": "546418746",
      "url": "https://gepris.dfg.de/gepris/projekt/546418746",
      "title": "Theoriespezifikation und Replizierbarkeit",
      "subject_area": "Sozialpsychologie und Arbeits- und Organisationspsychologie",
      "funding_period": "Förderung seit 2024",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 546418746",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Studien in den 2010er Jahren haben gezeigt, dass ein hoher Anteil der empirischen Ergebnisse, die seinerzeit in hochrangigen Fachzeitschriften veröffentlicht wurde, nicht replizierbar war. Dieser Befund hat zu Debatten über mögliche Gründe für die niedrigen Replikationsraten sowie über methodische Standards und Praktiken in der Forschung in Psychologie und anderen Wissenschaften geführt. Erste Diskussionen und Initiativen konzentrierten sich einerseits auf die Verbesserung der Standards für Transparenz und Offenheit und andererseits auf eine potenzielle Kontextabhängigkeit von Effekten. Die entwickelten Standards der Präregistrierung verlangen von Forschenden, genauere Hypothesen und Operationalisierungen a priori festzulegen. Dies zeigte ein grundlegenderes Problem auf. In einigen Bereichen der Psychologie liegen teilweise eher vage spezifizierte Theorien vor. Diese Unterspezifikation von Theorien und eine daraus resultierende schwache logische Verbindung zwischen Theorien und empirischen Tests können zu niedrigen Replikationsraten und einer erhöhten Falsch-Positiv-Rate beitragen. Dies könnte durch einen hohen Spielraum bei der Ableitung von Hypothesen, bei der Auswahl von Operationalisierungen und der Durchführung statistischer Tests bedingt sein. In dem geplanten Projekt wird dieser Zusammenhang zwischen Replizierbarkeit und dem Grad der theoretischen Spezifikation von Theorien empirisch untersucht. Hierfür wird zunächst eine Methodologie zur formalen Theoriespezifikation entwickelt, die besonders für den Replikationskontext angepasst ist. Diese wird verwendet, um 50 prominente Theorien der Sozialpsychologie zu spezifizieren und die Beziehung zwischen den Eigenschaften von Theorien - vor allem deren Spezifikationsgrad - und der Reproduzierbarkeit empirischer Befunde, die diese Theorie testen, zu analysieren. Wir werden dabei die Replizierbarkeit mittels eine z-Kurven Analyse schätzen und auch weiterer Methoden zur Testung der Robustheit dieser Schätzung heranziehen. Zur Berücksichtigung einer möglichst vollständigen Auswahl relevanter Artikel, die Aspekte der relevanten Theorien testen, wird eine auf Web-Scraping und Large Language Models basierende Methodologie entwickelt, die es erlaubt relevante Artikel automatisch zu identifizieren und darüber hinaus auch weitere potenzielle Kontroll- und Moderator-Variablen zu kodieren. Schließlich soll basierend auf den Theorie-Spezifikationen eine Open Theory Database entwickelt werden, welche der Forschungs-Community online zur Verfügung gestellt werden soll. Die Datenbank sowie die Methodologie zur Theoriespezifikation und zur Selektion relevanter Artikel sollen die technische und konzeptuelle Grundlage für eine effizientere kumulative Theorieentwicklung bereitstellen sowie systematische Analysen von Theorien und Empirie vereinfachen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und KognitionswissenschaftenInternationaler BezugÖsterreichKooperationspartnerinProfessorin Dr. Susann  Fiedler"
    },
    {
      "project_id": "464411255",
      "url": "https://gepris.dfg.de/gepris/projekt/464411255",
      "title": "Von \"wissenschaftlichen Arbeiten\" zum \"Arbeiten in der Wissenschaft\": Eine Analyse von Reformvorschlägen in agentenbasierten Modellen",
      "subject_area": "Allgemeine, Kognitive und Mathematische PsychologiePersönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464411255",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Dieser Antrag ist eine Fortsetzung des META-REP-Projekts „Wie kann Forschung zu vertrauenswürdigem Wissen kommen? Eine Analyse von Reformvorschlägen in agentenbasierten Modellen“. Dabei soll die bestehende Untersuchung des Wissenschaftssystems mit Hilfe von agentenbasierten Modellen (ABMs) erweitert werden, indem es Forschende als Menschen modelliert, mit ihrer Demographie, ihrem Lebenslauf und ihren strategischen Entscheidungen in einem akademischen Umfeld, das Arbeitgeber, Geldgeber und bestimmte Praktiken der Forschungsevaluation umfasst. ABMs, welche virtuelle, vereinfachte Repräsentationen realer Umgebungen darstellen, sind wertvolle Werkzeuge für die Untersuchung dieser Prozesse. In der ersten Förderphase dieses Projekts wurden mit ABMs verschiedene metawissenschaftliche Fragestellungen bearbeitet, wobei der Schwerpunkt auf individuellen Aktivitäten im Zusammenhang mit der Erstellung wissenschaftlicher Arbeiten lag, wie z. B. Replikationsstudien, Fehlerkorrektur sowie p-hacking. Die zweite Förderphase wird diese Modelle erweitern, indem sie auf strukturelle und institutionelle Aspekte der Wissenschaft und damit verbundene Reformvorschläge abzielt. Der Schwerpunkt wird damit von „akademischen Arbeiten“ – also den Outputs – auf das „Arbeiten in der Wissenschaft“ erweitert. Das Projekt wird demographische Daten von Forschenden sowie ihre Beschäftigungsverhältnisse mit einbeziehen. Auf diese Weise wird sich das Projekt auf Forschende als Menschen konzentrieren und analysieren, wie sich Strukturreformen auf deren Lebenslauf und Produktivität auswirken. Die zweite Förderphase besteht aus drei großen Themenbereichen: 1. Bewertung von Forschungsleistung: Inwiefern beeinflusst eine veränderte Anreizstruktur die Entscheidungen von Forschenden und damit letztlich die Qualität der Forschungsliteratur? 2. Die Nützlichkeit früher und später Interventionen: Wie wirksam sind Maßnahmen, die darauf abzielen, die Befähigung von Forschenden und folglich die Qualität ihrer Ergebnisse zu verbessern, im Vergleich zu post-hoc Fehlerkorrektur? 3. Institutionelle Karrierebedingungen: Analyse der Auswirkungen vertraglicher und rechtlicher Beschränkungen auf Forschende und ihre Ergebnisse. Im Rahmen des Projekts werden mehrere ABMs entwickelt, die durch eine Vielzahl empirischer Daten kalibriert werden. Außerdem wird eine empirische Evaluierungsstudie zu einem innovativen Ausbildungsprogramm (dem „Switch-to-Open“-Programm für akademische Arbeitsgruppen) durchgeführt, um umsetzbare Empfehlungen zu generieren. Die Erkenntnisse aus diesem Projekt werden zu den laufenden Debatten über das Wissenschaftssystem beitragen. Indem wir die gegenwärtigen Praktiken und die Konsequenzen von Reformvorschlägen mit Hilfe von ABMs verstehen, können wir Licht auf die „Wie“-Frage von META-REP werfen – „wie kann die Replizierbarkeit von Forschung verbessert werden“ – und letztendlich dazu beitragen, die Qualität der Forschung und die Arbeitsbedingungen der Forschenden zu verbessern.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    },
    {
      "project_id": "464394046",
      "url": "https://gepris.dfg.de/gepris/projekt/464394046",
      "title": "Welche Rolle spielt Messung bei der Replizierbarkeit von empirischen Befunden?",
      "subject_area": "Persönlichkeitspsychologie, Klinische und Medizinische Psychologie, Methoden",
      "funding_period": "Förderung seit 2021",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 464394046",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften",
      "description": "Im ersten Projektteil wurde gefunden, dass Berichte über itembasierte Skalen nicht nur in Originalforschung, sondern auch in Replikationsstudien intransparent und unvollständig sind. Zudem wird im ersten Teil untersucht, wie sich verschiedene Skalenmodifikationen wie das Entfernen von Items auf Replizierbarkeit und Effektheterogenität auswirken. Basierend darauf verfolgt der zweite Projektteil zwei Ziele: 1) Erhöhung der Transparenz und Verbesserung der Berichte über Messung in Forschungsveröffentlichungen und 2) Bereitstellung praktischer Ratschläge für Replizierende und Metawissenschaftler zum Umgang mit der Heterogenität von Messung über Studien hinweg. Um das erste Ziel zu erreichen, werden wir die Measures Checkliste entwickeln und evaluieren, die von Autoren verlangt, anzugeben, welche Skala sie verwendet, und ob und in welcher Form sie diese modifiziert haben. Wir werden die Measures Shiny App entwickeln, um das Ausfüllen durch automatisches Auslesen aus dem Manuskripttext zu erleichtern. Die Autoren können dann die Antworten überprüfen, überarbeiten und mit ihrem Manuskript einreichen. Die Measures Checkliste wird in sieben Schritten entwickelt und evaluiert werden, von der ersten Version über das Trainieren eines maschinellen Lernmodells, auf dem die Shiny-App basiert, die empirischen Überprüfung der Genauigkeit und der Durchführbarkeit bis zum Einsatz bei einer Fachzeitschrift mit anschließender Evaluierung. Das zweite Ziel wird a) durch die Entwicklung einer Taxonomie, bestehend aus Modifikationen und ihrer Auswirkungen auf Replikationserfolg und Effektheterogenität, und der Modifications Shiny App erreicht, durch die die Auswirkungen einer bestimmten Modifikation genauer abgeschätzt werden können. Dieses Tool kann sowohl a priori von Replizierenden verwendet werden, die erwägen, eine Skala zu modifizieren, als auch post hoc von Metawissenschaftlern. B) werden wir untersuchen, inwieweit die Messinvarianz (MI) bei gleicher Skala zwischen Original- und Replikationsstudie oder verschiedenen Replikationsstudien verletzt sein kann, ohne die Replizierbarkeit zu beeinträchtigen. Dafür verwenden wir drei komplementäre Ansätze: eine analytische Untersuchung, die Biases von Effekten bei Verletzungen von MI quantifiziert, eine Simulationsstudie, die dies auf die Schätzung von Faktorwerten ausweitet, und eine empirische Analyse existierender Datensätze. Basierend auf diesen Ergebnissen werden wir ein Tool zur Schätzung der Auswirkungen von MI-Verletzungen auf Replikationserfolg entwickeln. Dieses Projekt trägt zur Beantwortung der \"WARUM\"-Frage von META-REP bei, indem es MI-Verletzungen als Erklärungsfaktor für Replizierbarkeit untersucht. Der Fokus liegt auf der Beantwortung der \"WIE\"-Frage durch die Entwicklung und Evaluierung von Tools, die die Transparenz von Berichten verbessern und dadurch Maßstäbe verändern, sowie von solchen, die ermöglichen, die Auswirkungen von Skalenheterogenität zwischen Studien auf Replizierbarkeit zu beurteilen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2317: \nMETA-REP: Ein meta-wissenschaftliches Programm zur Analyse und Optimierung von Replizierbarkeit in den Verhaltens-, Sozial- und Kognitionswissenschaften"
    }
  ]
}