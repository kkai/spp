{
  "spp_number": "SPP 2377",
  "spp_title": "Disruptive Hauptspeichertechnologien",
  "spp_url": "https://gepris.dfg.de/gepris/projekt/460954224",
  "projects_count": 17,
  "projects": [
    {
      "project_id": "502388442",
      "url": "https://gepris.dfg.de/gepris/projekt/502388442",
      "title": "Balancieren von Berechnungen in speichernahen und im-Speicher heterogenen Systemen",
      "subject_area": "Softwaretechnik und ProgrammiersprachenRechnerarchitektur, eingebettete und massiv parallele Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502388442",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Compute-in-Memory- (CIM) und Compute-near-Memory- (CNM) Systeme, zusammenfassend als CINM bezeichnet, überwinden die Beschränkungen herkömmlicher Von-Neumann-Architekturen, indem sie die Leistung und Energieeffizienz erheblich steigern. Trotz erheblicher technologischer Fortschritte bleibt die effiziente Nutzung dieser Systeme eine große Herausforderung. In Phase I des SPP-2377 haben wir uns mit den Problemen der Programmierbarkeit dieser Systeme befasst, indem wir Cinnamon entwickelt haben, eine neuartige Compilertechnologie, die Optimierungen und Techniken integriert, die für verschiedene eigenständige CIM- und CNM-Architekturen zugeschnitten sind. Allerdings sind die CINM-Landschaft und die Anforderungen neuer Anwendungen in den letzten Jahren immer heterogener geworden. Moderne Systeme reichen heute von domänenspezifischen Beschleunigern mit dedizierten Multiplikations-Akkumulationseinheiten und analogen Komponenten bis hin zu speicherintegrierten Allzweck-CPUs - jedes System bietet einzigartige Kompromisse in Bezug auf Genauigkeit, Zuverlässigkeit und gemeinsame Datennutzung. Dieses Projekt (HetCIM-II) baut auf unserer soliden Grundlage und unserem tiefen Verständnis dieser Technologien auf und zielt darauf ab, diese neuen Herausforderungen durch die Entwicklung einer Infrastruktur für die Modellierung heterogener CINM-Systeme unter Verwendung realer Hardware und Simulation anzugehen. Diese Infrastruktur wird eine detaillierte Analyse dieser Systeme ermöglichen, so dass wir neue Hardware- und Software-Optimierungen für ihre effiziente Nutzung entwickeln können. Neuartige Kostenmodelle werden für CINM-Architekturen entworfen, in das Cinnamon-Framework integriert und als Entscheidungshilfe für Offloading und Optimierung verwendet. Darüber hinaus werden neue Applikations- und Operations-Mapping-Strategien sowie domänen- und Hardware-spezifische Optimierungen entwickelt, um die Fähigkeiten dieser Systeme voll auszuschöpfen. Für die Evaluierung werden neben den standardmäßigen CINM-Benchmark-Suiten auch Arbeitslasten aus den Bereichen maschinelles Lernen, Bioinformatik und Hochleistungsrechnen (HPC) verwendet. Wie bei HetCIM-I werden alle Optimierungs- und Simulations-Frameworks als Open-Source veröffentlicht, um die von der Gemeinschaft betriebene Forschung und Innovation in diesem Bereich zu fördern.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502457159",
      "url": "https://gepris.dfg.de/gepris/projekt/502457159",
      "title": "ccFOSSIL: Sichere Cache-Kohärenz für disaggregierten Speicher",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte SystemeRechnerarchitektur, eingebettete und massiv parallele Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502457159",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Das ccFOSSIL-Projekt baut auf zwei Beobachtungen aktueller Technologietrends auf: Erstens wurde Compute Express Link (CXL) als Nachfolgetechnologie zu NVM positioniert, oder allgemeiner, um verschiedene Arten von Beschleunigern oder Speichern mit Mehrwerteigenschaften mit einem Server zu verbinden. Zweitens hat die Prozessorhardware eine Komplexitätsstufe erreicht, auf der wir nicht mehr davon ausgehen können, dass der gesamten Hardware vertraut werden kann. Prozessorfehler wie Spectre und Meltdown läuteten eine neue Ära der Entdeckungen von Schwachstellen auf Hardware-Ebene ein. Kommende Systemarchitekturen in Rechenzentren verwenden CXL, um Rechengeräte mit großen Pools gemeinsam genutzter externer Speicher zu verbinden. Diese Pools verbessern die allgemeine Ressourcennutzung, indem sie es dem Rechenzentrumsbetreiber ermöglichen, einzelnen Servern dynamische Speicherstücke zuzuweisen. Dies ermöglicht es, den höheren Speicherbedarf eines Servers zu erfüllen, wenn ein anderer seinen Anteil nicht ausnutzt. Herkömmliches fest verdrahtetes DRAM innerhalb des Servers mit geringem Speicherbedarf könnte nicht so genutzt werden. CXL-basierte Speichersysteme weisen jedoch eine große Trusted Computing Base (TCB) auf, da im Wesentlichen allen Geräten im gesamten CXL-Netzwerk vertraut werden muss. Idealerweise sollte eine bestimmte Anwendung nur den CPUs, Speichern und Beschleunigern vertrauen, die sie tatsächlich verwendet, was zu einer kleinen TCB und einer starken Isolation zwischen Rechenzentrumskunden führt. Eine solche Isolierung verhindert, dass sich Angriffe, die von einem Kunden durchgeführt werden, über das gesamte CXL-Netzwerk ausbreiten können. Wir schlagen selektive Cache-Kohärenz als Lösung vor. Es erfordert Änderungen an der zugrunde liegenden Hardwarearchitektur, so dass der Cache-Kohärenzverkehr durch eine zusätzliche Hardwarekomponente gefiltert wird, die außerhalb von Speicherpool- und Prozessorimplementierungen liegt. Diese Komponente ist so konfiguriert, dass sie nur zwischen bestimmten Partnern und in bestimmten Adressfenstern den Kohärenzverkehr zulässt. Im Rahmen des ccFOSSIL-Projekts werden wir eine solche Komponente in der Mikrokern-basierten System-on-Chip-Architektur M³ entwerfen und implementieren. Wir werden das Ergebnis mit relevanten Rechenzentrums- und CXL-Workloads prototypisieren und auswerten.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502308721",
      "url": "https://gepris.dfg.de/gepris/projekt/502308721",
      "title": "Co-Design von rekonfigurierbaren Architekturen und Echtzeitsystemen für nicht-flüchtige Hauptspeicher (ARTS-NVM)",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502308721",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Anwendungen für eingebettete Systeme erfordern eine hohe Rechenleistung bei geringem Leistungsverbrauch (i.e. elektrisch) und größerem Speicherbedarf. Diese teilweise widersprüchlichen Randbedingungen erfordern neue Methoden und/oder neue Systemarchitekturen. Neben den potenziellen Vorteilen müssen jedoch auch Herausforderungen bewältigt werden, um von diesen neuen Eigenschaften zu profitieren. Dieses Forschungsprojekt zielt auf die Entwicklung von NVM-basierten rekonfigurierbaren Architekturen und Timing-Analysen ab, welche NVMs sicher als Hauptspeicher in eingebetteten Echtzeitsystemen und/oder als rekonfigurierbare Strukturen nutzen können, indem die Zeit-Vorhersagbarkeit und die Qualität von Wear-Leveling-Systemroutinen deutlich verbessert werden. Obwohl es verschiedene Ansaetze von disruptiver Designproblemen und Worst-Case-Timing-Analysen gibt, können diese das Gesamt-System mit NVMs in Echtzeitsystemen noch nicht auf einem Niveau modellieren, analysieren und betreiben, wie dies für den sicheren Betrieb in einer Vielzahl eingebetteter Computer-Systeme erforderlich ist. Mit dem Fortschreiten komplexer eingebetteter Systemanwendungen werden in naher Zukunft ein hoher Speicherbedarf und ein geringer Leistungsbedarf von entscheidender Bedeutung sein, was den Bedarf an NVM-freundlichen Echtzeitbetriebssystemen und rekonfigurierbaren Strukturen erfordert. Wir haben die folgenden Ziele: i) Entwicklung von Task-Modellen und zeit-bewussten Analysen, um sichere Obergrenzen für Worst-Case-Ausführungszeiten und Reaktionszeiten abzuleiten und dabei wichtige NVM-spezifische Eigenschaften zu berücksichtigen. ii) Entwicklung von Architektur- und Systemebenenansätzen zur Verbesserung der Zuverlässigkeit und Anpassungsfähigkeit von NVM-basierten FPGAs durch Optimierung der Ressourcenverwaltung und der Rekonfigurationsstrategien bei gleichzeitiger Einhaltung von Leistungsanforderungen unter den NVM-Randbedingungen. iii) Verbesserung der Systemsoftware zur Unterstützung von NVM-Technologien durch Verfeinerung der Speicherverwaltung, Optimierung speicherabgebildeter Schnittstellen für Controller und Integration von Monitor-Funktionen zur Verbesserung der Online-Zugangskontrolle. In der Literatur vorgeschlagene Lösungen haben einige individuelle Probleme adressiert. In Anbetracht des erforderlichen Zeitaufwands wurde der zeitlichen Vorhersagbarkeit jedoch nicht genügend Aufmerksamkeit gewidmet. Darüber hinaus ist NVM-Beanspruchung (i.e. Stress) des NVM unter gegebenen Zeitanforderungen noch ein offenes Problem. Damit ist es uns möglich, bereits in frühen Entwurfsphasen neuartige Methoden, Analysen und Optimierungen einzubringen. Wir gehen davon aus, dass die Forschungsergebnisse dieses Projekts eine neue Perspektive auf eingebettete Echtzeitsysteme für disruptive Speichertechnologien mit zeitbewussten, NVM-basierten rekonfigurierbaren Architekturen bieten und die Bandbreite der wissenschaftlichen Ergebnisse des SPP 2377 bereichern werden.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "501680474",
      "url": "https://gepris.dfg.de/gepris/projekt/501680474",
      "title": "CXL-Bridge: CXL controllers for heterogeneous memory architectures",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte SystemeRechnerarchitektur, eingebettete und massiv parallele Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 501680474",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "CXL ist eine sich schnell entwickelnde Netzwerktechnologie, die eine schnelle Kommunikation auf Rack-Ebene zwischen Rechenknoten und Speichergeräten ermöglicht. Durch die Konsolidierung des Speichers in gemeinsam genutzten Pools und deren Bereitstellung als physische Bereiche ermöglicht CXL CPUs verschiedener Rechner den komfortablen Zugriff auf umfangreiche Speicherressourcen mithilfe herkömmlicher Lade-/Speicheranweisungen. Um die Datenkohärenz im gemeinsam genutzten Speicher zu gewährleisten, spezifiziert CXL ein eigenes MESI-ähnliches Cache-Kohärenzprotokoll und bietet so eine effiziente und hardwarebasierte Lösung für die Interaktion mit Remote-Speicher. Die CPU-internen Cache-Kohärenzprotokolle sind jedoch eng mit den Speichersubsystemen moderner CPUs integriert und auf deren spezifische Architekturen und Speicherkonsistenzmodelle (MCMs) zugeschnitten. Diese enge Kopplung stellt erhebliche Herausforderungen bei der Erweiterung oder Zusammenarbeit mit anderen externen Protokollen wie CXL dar, insbesondere in heterogenen Systemen, in denen Geräte unterschiedliche Protokolle und MCMs verwenden. In diesem Forschungsvorhaben befassen wir uns mit der Integration des CXL-Cache-Kohärenzprotokolls in herstellerspezifische Protokolle durch die Entwicklung eines neuartigen CXL-Bridge-Generators. Unser vorgeschlagenes System synthetisiert und verifiziert CXL-Bridges automatisch und ermöglicht so eine nahtlose Interoperabilität zwischen verschiedenen Rechenknoten und anderen CXL-Geräten, ohne die internen Protokolle zu ändern. Die generierten Bridges garantieren einen störungsfreien Betrieb und die Einhaltung der Speicherkonsistenzmodelle von CXL- und Hostsystemen. Dies gewährleistet Korrektheit und Leistung in heterogenen Umgebungen. Die konkreten Ergebnisse dieser Arbeit umfassen: (1) ein Compound-Kohärenzprotokoll-Framework zur Integration heterogener CPUs und CXL-Speichersysteme; (2) einen funktionalen, durchgängigen CXL-Bridge-Generator zur Synthese und Evaluierung der Protokollfusion; (3) ein effizientes, auf hierarchische CXL-Systeme zugeschnittenes Verifikationsframework, das die Sicherheits- und Liveness-Eigenschaften der generierten Bridges gewährleistet; und (4) eine umfassende Performanceanalyse mittels Gem5-Simulationen zur Bewertung der Leistung der Protokollfusion und unserer Bridge-Designs.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "567410490",
      "url": "https://gepris.dfg.de/gepris/projekt/567410490",
      "title": "DRAMaOS: DRAM-aware OS",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte SystemeRechnerarchitektur, eingebettete und massiv parallele Systeme",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 567410490",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Der Hauptspeicher eines Rechensystems ist wohl die grundlegendste Art von Speicher, den das Betriebssystem (BS) für Benutzerprozesse, das IO-Subsystem und den Kernel selbst verwalten muss. Die Speicherseite ist zur Einheit für alle Verwendungen von Hauptspeichers geworden, und selbst der Zugriff auf Festplattendateien wird vom Kernel über seitenbasierte Speicherabbildungen realisiert. Diese Gleichbehandlung von Speicheranforderungen auf Seitenrahmen-Granularität war zentral für die Eleganz des Mach-Speichermodells und ist immer noch die Grundlage der Speichersubsysteme in allen modernen Betriebssystemen. Auf der Hardwareseite wird der Hauptspeicher meist als DRAM bereitgestellt, bei dem Fortschritte in der Hardwaredichte den Aufbau von Systemen mit TiB Hauptspeicher ermöglicht haben. Intern verwenden moderne DRAM-Subsysteme komplexe Topologien mit mehreren Kanälen oder Pseudokanälen, die den Speicher und seine Zugriffe auf Ranks, Bankgruppen, Bänke und Zeilen verteilen, um damit nichtfunktionale Eigenschaften wie Zugriffslatenz und Durchsatz, Energieverbrauch, Robustheit und Sicherheit zu verbessern. Ein modernes DRAM-System ist hochgradig hierarchisch aufgebaut und Zugriffe auf verschiedene Adressen können sich unterschiedlich verhalten. In gewissem Sinne kann modernes DRAM als ein eigenständiges (kleines) heterogenes Speichersystem (HMS) betrachtet werden. Zukünftige Standards wie LPDDR6, DDR6 oder HBM4 bieten noch mehr Funktionen, um die Verwendung bezüglich (konkurriernder) nichtfunktionaler Eigenschaften zu optimieren. Neue Trends, wie CXL.mem und Processing-in-Memory (PIM), fügen der DRAM-Hierarchie weitere Dimensionen hinzu. Bislang bleiben jedoch wesentliche Teile dieser Hierarchie und deren Eigenschaften dem Betriebssystem (BS) hinter dem Speichercontroller (SC) verborgen. Es würden sich jedoch erhebliche Optimierungsmöglichkeiten ergeben, wenn das BS ein tieferes Verständnis für die DRAM-Struktur hätte und der SC stärker auf die Anforderungen des Betriebssystems abgestimmt wäre. Letzterer benötigt bereits detaillierte Kenntnisse der internen DRAM-Hierarchie, um korrekt zu funktionieren, und ist damit ideal positioniert, um dem BS zusätzliche Metadaten über das Speichersystem zur Verfügung zu stellen. Darüber hinaus könnte das BS auch häufige Verwaltungsaufgaben, wie das Nullen oder Kopieren von Speichersseiten, an den Controller auslagern. In DRAMaOS untersuchen wir die Schnittstelle zwischen BS und SC von beiden Seiten. Wir erforschen das Potenzial eines BS-SC-Codesign-Ansatzes zur Verbesserung der nicht-funktionalen Eigenschaften (z. B. Energieverbrauch) DRAM-intensiver Systeme durch anpassbare DRAM-sensitive BS-Strategien und BS-sensitive MC-Funktionalität.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502196634",
      "url": "https://gepris.dfg.de/gepris/projekt/502196634",
      "title": "Ein universeller Framework für zuverlässiges Computing-in-Memory basierend auf aufkommenden nicht-flüchtigen Speichern (CIMware)",
      "subject_area": "Rechnerarchitektur, eingebettete und massiv parallele Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502196634",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Computing-in-Memory (CIM) ist ein aufstrebendes Paradigma, das Speicher- und Verarbeitungseinheiten eng integriert, um den Zeit- und Energieaufwand für Datenbewegungen innerhalb digitaler Architekturen zu minimieren. Unter den verschiedenen neuartigen Gerätetechnologien sind nichtflüchtige Speichertechnologien (Non-Volatile Memory, NVM) – wie Spin-Transfer-Torque (STT) MRAM, Resistive RAM (ReRAM) und Phasenwechselspeicher (PCM) – besonders vielversprechend für die Umsetzung von CIM. Diese memristiven und spintronischen Bauelemente dienen sowohl als Speicher- als auch als Recheneinheiten, wodurch sie eine höhere Systemkomplexität und Leistung ermöglichen und gleichzeitig den Energieverbrauch erheblich reduzieren. Trotz des wachsenden Interesses an CIM bleiben mehrere grundlegende Herausforderungen bestehen. Die architektonische Gestaltung von CIM-Systemen und ihre Integration in Speicherhierarchien sind weiterhin offene Forschungsfragen. Darüber hinaus zeigen In-Memory-Computing-Architekturen, die auf neuen NVM-Technologien basieren, großes Potenzial, jedoch müssen viele Probleme im Zusammenhang mit der Gerätezuverlässigkeit, der technischen Reife und der Doppelfunktion (Speicherung und Berechnung) gelöst werden. Im Gegensatz zur etablierten CMOS-Technologie – die von über fünf Jahrzehnten der Optimierung profitiert hat – weisen diese neuartigen Speicherbauelemente inhärente stochastische Effekte und Prozessvariationen auf. Dies erschwert es, die strengen Zuverlässigkeitsanforderungen moderner Rechensysteme zu erfüllen. Dieses Projekt zielt darauf ab, die Lücke zwischen technologischen Fortschritten im Bereich neuartiger nichtflüchtiger Speicher und architekturbezogener Designforschung für zuverlässige und energieeffiziente CIM-Systeme zu schließen. Konkret werden wir eine Bibliothek zuverlässiger und energieeffizienter CIMSchaltungsprimitive auf Basis verschiedener memristiver und spintronischer Technologien entwickeln. Diese verfolgt zwei zentrale Ziele: 1- Praktische CIM-Architekturen ermöglichen, indem ein NVMCIM-Speicher-Compiler auf Hardware-Ebene sowie eine Application Programming Interface (API) für CIM-fähige Architekturen auf Software-Ebene entwickelt wird.  2- Präzise, technologiebezogene Architekturmodelle bereitstellen, um das Potenzial verschiedener NVM-Technologien (MRAM, PCM, ReRAM) für CIM-Architekturen zu bewerten und zu benchmarken. Durch die Entwicklung dieser technologiebewussten Modelle und architektonischen Erkenntnisse wird das Projekt weitere Fortschritte in den Bereichen Software, Compiler-Design und CIM Systemforschung ermöglichen. Dies wird letztendlich die Adoption energieeffizienter und zuverlässiger CIMComputing-Paradigmen beschleunigen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502268500",
      "url": "https://gepris.dfg.de/gepris/projekt/502268500",
      "title": "Eine allgemeine Speicher-Engine für moderne Speicherhierarchien",
      "subject_area": "Rechnerarchitektur, eingebettete und massiv parallele SystemeDatenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502268500",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Die wissenschaftliche Forschung wird zunehmend von datenintensiven Problemen bestimmt. Da die Komplexität der untersuchten Probleme zunimmt, steigt auch der Bedarf an hohem Datendurchsatz und -kapazität. Das weltweit produzierte Datenvolumen verdoppelt sich etwa alle zwei Jahre, was zu einer exponentiellen Datenflut führt. Diese Datenflut stellt eine direkte Herausforderung für Datenbankmanagementsysteme und Dateisysteme dar, die die Grundlage für eine effiziente Datenanalyse und -verwaltung bilden. Diese Systeme verwenden verschiedene Speichergeräte, die traditionell in Primär-, Sekundär- und Tertiärspeicher unterteilt waren. Mit der Einführung der disruptiven Technologie des nichtflüchtigen Arbeitsspeichers (NVRAM) begannen diese Klassen jedoch miteinander zu verschmelzen, was zu heterogenen Speicherarchitekturen führte, bei denen jedes Speichergerät sehr unterschiedliche Leistungsmerkmale aufweist (z. B. Persistenz, Speicherkapazität, Latenz). Eine große Herausforderung ist daher die Ausnutzung der spezifischen Leistungscharakteristika dieser Speichergeräte.Zu diesem Zweck wird SMASH die Vorteile einer allgemeinen Speicher-Engine untersuchen, die eine heterogene Speicherlandschaft verwaltet, einschließlich herkömmlicher Speichergeräte und nichtflüchtiger Speichertechnologien. Das Herzstück dieser Speicher-Engine werden B-epsilon-Bäume sein, da diese zur effizienten Nutzung dieser unterschiedlichen Geräte verwendet werden können. Darüber hinaus werden Strategien zur Datenplatzierung und -migration untersucht, um den durch die Übertragung von Daten zwischen verschiedenen Geräten verursachten Overhead zu minimieren. Durch den Wegfall der Notwendigkeit flüchtiger Caches kann die Datenkonsistenz besser sichergestellt werden. Auf der Anwendungsseite wird die Speicher-Engine Key-Value- und Objekt-Schnittstellen bieten, die für eine Vielzahl von Anwendungsfällen genutzt werden können, zum Beispiel für das Hochleistungsrechnen (HPC) und für Datenbankmanagementsysteme. Aufgrund der immer größer werdenden Kluft zwischen der Leistung von Rechen- und Speichergeräten sowie deren stagnierender Zugriffsleistung sind außerdem Techniken zur Datenreduzierung sehr gefragt, um den Bandbreitenbedarf beim Speichern und Abrufen von Daten zu verringern. Wir werden daher Forschungsarbeiten zu Datentransformationen im Allgemeinen und zu den Möglichkeiten externer und beschleunigter Transformationen durchführen. Übliche HPC-Workflows werden durch die Integration von SMASH in das bestehende JULEA-Storage-Framework unterstützt, während Datenbanksysteme die Schnittstelle von SMASH direkt nutzen können, um Daten zu speichern oder abzurufen.Das Konsortium wird von der Intel Corporation unterstützt, insbesondere bei der Hardware-Beschleunigung von Datentransformationen, und arbeitet aktiv mit anderen Projekten innerhalb des SPP 2377 zusammen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive HauptspeichertechnologienEhemaliger AntragstellerDr.-Ing. David  Broneske, bis 8/2022"
    },
    {
      "project_id": "502213043",
      "url": "https://gepris.dfg.de/gepris/projekt/502213043",
      "title": "HYPNOS - Co-Design persistenter energie-effizienter und leistungsstarker eingebetteter Prozessorsyteme mit hybrid-volatiler Speicherorganisation",
      "subject_area": "Rechnerarchitektur, eingebettete und massiv parallele SystemeSoftwaretechnik und Programmiersprachen",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502213043",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Project HYPNOS untersucht den Einsatz emergenter nichtflüchtiger Speichertechnologien (engl. NVM) nicht nur im Bereich des Hauptspeichers, sondern über die gesamte Cache-Hierarchie und Register moderner eingebetteter Prozessoren hinweg. Insbesondere wird untersucht, welche Vorteile eine solche gemischt volatile Speicherhierarchie hinsichtlich erzielbarer Taktraten und Senkung des Energieverbrauchs für eine Vielzahl von Anwendungen im Bereich eingebetteter Systeme bringt und dabei gleichzeitig Persistenz von Datenstrukturen, Programmausführung und Prozessorzustand einfach und effizient zusichert. Zum einen können emergente Prozessoren aus dem IoT-Bereich mit vollständig nichtflüchtigen Speichern (sog. NVPs) nur mit relativ geringen Taktraten betrieben werden aufgrund deutlich höherer Schreibzeiten für NVM-Speicher als auch um Größenordnung geringerer sog. Endurance als z.B. SRAM. Zum anderen fordern existierende Systeme mit NVM-Hauptspeichererweiterungen dem Programmierer ab, Datenstrukturen explizit durch die Speicherhierarchie durch Spezialbefehle zu persistieren. HYPNOS (benannt nach dem griechischen Gott des Schlafes) untersucht den Konflikt zwischen Performance, Endurance und Programmierbarkeit systematisch auf der Basis in der ersten Phase systematisch explorierter CPU-Architekturen mit hybriden (gemischt flüchtig/nichtflüchtigen) Cache-Strukturen. Unsere Untersuchungen in der zweiten Phase umfassen: a) Implementierung und Compiler-Unterstützung für HW-Transaktionen in Architekturen mit hybrid-volatilen Caches zur Gewährleistung von Fehler-Atomarität im Multi-Core-Kontext; b) Optimierung von Performance und Energieverbrauch hybrider Cache-Architekturen durch Einführung von Programmannotationen (\"Hints\") mit Informationen über das Lese- und Schreibverhalten statisch analysierter und profilierter Datensegmente und Nutzung dieser Hinweise innerhalb der Cache-Controller der hybriden Cache-Architektur; c) \"Volatility on demand\" erforscht Mechanismen, um selektiv zu vermeiden, dass alle Daten und Code bei Stromausfällen persistent gespeichert werden müssen. Es umfasst softwaredefinierte Volatilitätspräferenzen, Hardware-Techniken für Absturzkonsistenz und zur konsistenten Wiederherstellung sowie Strategien zur Optimierung der Energieeffizienz in intermittierendem Computing. d) Die in a),b), und c) entwickelten Konzepte sollen systematisch evaluiert werden in Bezug auf Performance, Energieverbrauch und Backup- und Recovery-Zeiten durch Erweiterung der in der ersten Phase entwickelten gem5-basierten Simulationsplattform. Als Anwendungen sollen vorrangig IoT-Benchmarks und Szenarien stark eingeschränkter verfügbarer Energie untersucht werden, u.a. aus den Bereichen der Sensorsignalverarbeitung sowie Steuerungs- und Regelungsanwendungen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502616169",
      "url": "https://gepris.dfg.de/gepris/projekt/502616169",
      "title": "Koordinationsfonds",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502616169",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Seit Pioniere wie Konrad Zuse und John von Neumann den Grundstein für die heutigen Computer gelegt haben, ist der Speicher eine zentrale Komponente in praktisch jedem System. Im Laufe der Jahrzehnte hat sich die verwendete Hardware-Technologie weiterentwickelt, was zu größeren Kapazitäten und höheren Geschwindigkeiten führte, doch wesentliche Eigenschaften der Schnittstelle zwischen Hardware und Software sind gleich geblieben: Hauptspeicher ist flüchtig, passiv und weitgehend homogen. Mittlerweile sind diese typischen Speichereigenschaften in der Erwartung der Software-Entwickler fest verankert und manifestieren sich dementsprechend in deren Produkten. Derzeit beobachten wir nun eine Welle von Innovationen im Bereich der Speicher, die diese Annahmen zunichtemachen und in diesem Sinne für die komplette Software-Industrie und Informatik disruptiv sind. Insgesamt versprechen die aktuellen Innovationen vielfältige Verbesserungen für alle Computersysteme, zum Beispiel geringerer Energieverbrauch, höhere Verarbeitungsleistung, mehr Verlässlichkeit sowie Vereinfachung und dadurch Kostenreduktion. Wie man jedoch all diese Möglichkeiten für existierende und zukünftig komplett neu konzipierte Software (und damit Gesamtsysteme) nutzt, ist bisher weitgehend unklar. Das Ziel dieses Schwerpunktprogramms ist es daher, die Potentiale der aktuellen Entwicklungen im Bereich der Hauptspeichertechnologien und -architekturen zu erforschen und Methoden zu entwickeln, um diese trotz ihres disruptiven Charakters für System- und Anwendungssoftware zu erschließen. Um disruptive Speichertechnologien und ihre Auswirkungen auf die gesamte Speicherhierarchie zu beherrschen, sind vereinte Forschungsanstrengungen auf allen Ebenen des klassischen Systemsoftware-Stapels erforderlich.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502228341",
      "url": "https://gepris.dfg.de/gepris/projekt/502228341",
      "title": "Memento: Energieeffiziente Speicherplatzierung",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502228341",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Die fortschreitende Entwicklung von byteaddressierbarem nichtflüchtigem Hauptspeicher (NVM), High Bandwidth Memory (HBM) und Compute Express Link (CXL) hat in jüngster Zeit mehrere Speichertechnologien und neue Hochgeschwindigkeitsverbindungen zwischen Computerspeichern als ernsthafte Alternativen zu herkömmlichen Speichertechnologien und -anbindungen etabliert. Erstmals sind Systemarchitekturen realisierbar, die heterogene Speichertypen innerhalb eines Computersystems nutzen. Dies eröffnet neue Möglichkeiten, neben der Systemperformance auch nicht-funktionale Systemeigenschaften wie Leistungsaufnahme, Energiebedarf und CO2-Fußabdruck gezielt zu verbessern. Um diese Ziele zu erreichen, müssen allerdings die Systemsoftware und Programmiermodelle auf der Softwareebene aufholen und angepasst werden. Das Memento-Projekt hat sich zum Ziel gesetzt, den aktuellen Stand der Forschung in diesem Bereich voranzutreiben, indem die Speicherverteilungsstrategien des Betriebssystems im Hinblick auf neue, heterogene Speichertechnologien und -anbindungen erweitert werden, um den neuen Anforderungen der Hardware auch in der Systemsoftware gerecht zu werden. Das Projekt verfolgt in seiner Fortsetzung den Memory-Governor-Ansatz und erweitert diesen auf Basis der in der ersten Projektphase erzielten Ergebnisse. Im Vordergrund stehen hierbei die Erweiterung des Memory Governors als zentralen Komponente: Zur verbesserten Abbildung der Anwendungen mit unterschiedlichen Speicherzugriffsmustern entwirft und entwickelt Memento ein softwarebasiertes Getriebe (engl. gearbox), das zur Laufzeit anwendungsspezifische Systemeinstellungen in Abhängigkeit von den getroffenen Speicherzuweisungen des Memory Governor vornimmt. Insbesondere die dynamische Ermittlung von Speicherzugriffsmustern zur Laufzeit muss zwingend mit einer geringen Zusatzlast für das Computersystem, damit möglichst \\glqq geräuscharm\\grqq{} und ohne implizite Erzeugung von Hintergrundrauschen im Betriebssystem einhergehen. Zu diesem Zweck entwickelt Memento eine hardwareunterstützte Assistenzeinheit für die Nachvollziehbarkeit von Speicherzugriffen. Orthogonal zu diesen funktionalen Erweiterungen im Projekt steht in der zweiten Projektphase die Erweiterung des Memento Memory Governors zur gezielten Reduzierung des CO2-Fußabdrucks im Mittelpunkt der Forschungsarbeiten, der die energieeffizienten Speicherplatzierungsentscheidungen ermöglicht. Die Erweiterungen führen potenziell zu Schwachstellen in der Systemsoftware, da durch die enge Verzahnung von Anwendungen und Betriebssystem das Verhalten des Betriebssystems von Userspace-Prozesse gezielt beeinflusst wird. Um dem entgegenzuwirken, sieht Memento ein betriebssystembasiertes Schutzkonzept vor, das potenzielle Angriffspunkte proaktiv mitigiert. Ein umfassender Vorher-Nachher-Vergleich evaluiert die Projektergebnisse mit verfügbaren und neu veröffentlichten Speichertechnologien (z.B. CXL) und vergleicht diese mit traditionellen Systemen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502384507",
      "url": "https://gepris.dfg.de/gepris/projekt/502384507",
      "title": "Memory Diplomat (MD)",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502384507",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Neuartige und alternative Speicherarchitekturen, wie zum Beispiel nichtflüchtige Speicher (engl. non-volatile memory (NVM)) oder Speicher mit sehr hoher Bandbreite (engl. high bandwidth memory (HBM)), eröffnen Anwendungen, im besonderen datenzentrierten Anwendungen wie zum Beispiel Datenbanksysteme, und Betriebssystemen erweiterte Möglichkeiten zur optimierten Nutzung der Speichertechnologien. Beispielsweise zeigen einige nichtflüchtige Speicher eine verringerte Lebensdauer, weshalb Speicherzugriffe gleichmäßig über den Speicherbereich verteilt werden müssen (engl. wear-leveling). Speicher mit hoher Bandbreite sind häufig nur in geringen Kapazitäten verfügbar, weshalb nur bestimmte Teile eines Programms in diesen Speicher gelegt werden können. Die bestmögliche Auswahl solcher Inhalte ist eine Optimierungsaufgabe. Wenn Anwendungen solche Optimierungen durchführen wollen, benötigen diese aktuell detailliertes Wissen über die verbauten Speichertechnologien und die Eigenschaften. In gleichem Maße benötigt das Betriebssystem und die Speicherhardware ein detailliertes Wissen über die Anwendung um den Speicher entsprechend verwalten zu können.In diesem Projekt stellen wir einen alternativen Ansatz vor, der detailliertes Wissen der Anwendung über die Speicherhardware überflüssig macht und ebenfalls detailliertes Wissen der Hardware und des Betriebssystems über die Applikation überflüssig macht. Eine zentrale Softwareinstanz namens Memory Diplomat betrachtet und bewertet alle Bedürfnisse, Bedingungen und Wünsche der Anwendung und der Hardware. Daraufhin entscheidet der Memory Diplomat über entsprechende Optimierungen für die Nutzung des Speichers. Um dies zu erreichen, schlagen wir vor, traditionelle Speicherschnittstellen zu überdenken. Daraus ergeben sich erweiterte Schnittstellen, über die Verhaltenseigenschaften der Anwendung und der Hardware definiert werden können. Diese Verhaltenseigenschaften sind so gewählt, dass sie zum einen abstrakt sind und möglichst viele Speichertechnologien und Anwendungen abdecken können, zum anderen aber spezifisch genug sind um die technologischen Besonderheiten vollständig abdecken und repräsentieren zu können. Die Verhaltenseigenschaften bilden jeweils Gegenstücke, die daraufhin vom Memory Diplomat betrachtet und entsprechend durch Optimierungsverfahren verknüpft werden.Während der gesamten Projektlaufzeit werden nicht nur Konzepte für den Memory Diplomat erarbeitet, sondern auch entworfene Methoden auf Grundlage von tatsächlichen Implementierungen evaluiert und bewertet.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "501887536",
      "url": "https://gepris.dfg.de/gepris/projekt/501887536",
      "title": "ParPerOS: Parallel Persistency OS",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 501887536",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Die Verwaltung von Speicherressourcen war schon immer eine Kernaufgabe des Betriebssystems. Die Entwickler von Betriebssystemen sehen sich jetzt jedoch mit bahnbrechenden Veränderungen in der Speichertechnologie konfrontiert: neue Speichertypen, mehr Arten von Rechnenelementen wie Smart NICs, GPGPUs oder FPGA-basierte Beschleuniger und die aufkommende CXL-Technologie. Mit CXL können Peripheriegeräte nicht nur Cache-kohärent auf den physischen Speicher des Hosts zugreifen, sondern der Speicher wird auch zu einer umverteilbaren Ressource. Diese Hardware-Entwicklungen stellen sowohl die klassische Speicherhierarchie als auch die Speicherverwaltung innerhalb des Kerns in Frage. In ParPerOS erforschen wir neue Abstraktionen für eine einheitliche, effiziente und optional crash-konsistente Low-Level Speicherverwaltung von Datenobjekten in heterogenen und disaggregierten Speichersystemen. Diese Systeme bestehen aus flüchtigem, verteiltem und anderem Arten von Hauptspeicher, auf die verschiedene Verarbeitungselemente (CPU, GPU, NIC usw.) parallel zugreifen, entweder über die klassische DIMM-Schnittstelle oder über PCIe/CXL.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502352642",
      "url": "https://gepris.dfg.de/gepris/projekt/502352642",
      "title": "Processing-In-Memory Primitive für das Datenmanagement (PIMPMe)",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502352642",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Die laufenden Entwicklungen auf dem Gebiet der Speichertechnologie eröffnen ein großes Potenzial für den Aufbau hocheffizienter datenintensiver Systeme, die den Herausforderungen moderner Anwendungen gerecht werden. Gleichzeitig müssen traditionelle Annahmen überdacht werden, um diese Technologie voll ausschöpfen zu können. In diesem Projekt wollen wir den Nutzen speicherzentrierter Computing-Paradigmen (Processing-in-Memory PIM) untersuchen: Wir werden die Verlagerung von Berechnungen in den Speicher erforschen, um die zwischen Speicher und CPU zu übertragende Datenmenge zu verringern und auf diese Weise die Bandbreite zu erhöhen, die CPU-Belastung für Berechnungen zu verringern und letztlich den Energieverbrauch moderner IT-Systeme zu senken. Wir planen die Ergebnisse der ersten Projektphase zur Auslagerung von Datenbankoperation in PIM-Speicher zu erweitern. Konkret sind zwei Dimensionen der Erweiterung vorgesehen: (1) PIM-Abstraktionen: Während wir in der ersten Phase Primitive betrachtet haben, die auf die UPMEM-Speichertechnologie zugeschnitten sind, und aktuell noch an FPGA-Unterstützung arbeiten, planen wir in der zweiten Phase, Abstraktionen auf höherer Ebene zu entwerfen und zu entwickeln, die verschiedene Speicher- und Ausführungsmodelle unterstützen. (2) Verteiltes Rechnen: Mit dem Aufkommen von Interconnects wie CXL.mem aber auch mit Netzwerktechnologien wie RDMA werden Shared-Memory-Infrastrukturen verfügbar, bei denen mehrere Rechenknoten auf denselben Hauptspeicher zugreifen und Berechnungen auslagern können. Im Projekt sollen die Herausforderungen und Möglichkeiten solcher Infrastrukturen im spezifischen Kontext der verteilten Datenbankverarbeitung untersucht werden.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "568456166",
      "url": "https://gepris.dfg.de/gepris/projekt/568456166",
      "title": "Puffer mit Vorteilen: Elastische Speicherhierarchien für speicherintensive Anwendungen",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2025",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 568456166",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Das Gesamtziel dieses Projekts besteht darin, Hauptspeicher-Datenbanksysteme in die Lage zu versetzen, von einer elastischen Speicherhierarchie zu profitieren. Dieser Ansatz ist nicht nur aufgrund der Einbeziehung von Speichertechnologien wie NVRAM, HBM, PIM und NMC-Komponenten bahnbrechend, sondern vor allem aufgrund eines Auswahlprozesses geeigneter Komponenten und Technologien, die in der elastischen Speicherhierarchie verwendet werden, wie z. B. Speicherkomprimierung, GPU-Beschleunigung oder die Verwendung von Remote-Speicherressourcen. Die tatsächliche Konfiguration der Speicherhierarchie für einen bestimmten Anwendungsfall wird auf einer Mehrkriterienanalyse der Abwägung zwischen verschiedenen nicht-funktionalen Parametern eines Systems beruhen. Dabei gehen wir davon aus, dass das System den Prinzipien des Autonomic Computing folgt: Es ist anpassungsfähig an nicht-funktionale Eigenschaften und an Veränderungen in der Verfügbarkeit der Komponenten der Speicherhierarchie.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502565817",
      "url": "https://gepris.dfg.de/gepris/projekt/502565817",
      "title": "SMAUG: Systemübergreifende Modellierung und optimierte Nutzung disruptiver Hauptspeichertechnologien",
      "subject_area": "Sicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502565817",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Hauptspeicher ist nach den Recheneinheiten das wichtigste Betriebsmittel in einem Rechnersystem, ohne das eine Datenverarbeitung de facto unmöglich wäre. Seit mehreren Jahrzehnten werden verschiedene Arten von RAM (“Random Access Memory”) als Hauptspeicher genutzt. RAM wurde technologisch fortentwickelt und bekam so größere Kapazitäten, niedrigere Zugriffslatenzen und größere Datenraten, doch die prinzipiellen Eigenschaften des Hauptspeichers blieben unverändert. Er ist traditionell homogen und byteweise adressierbar. Speicherinhalte sind flüchtig, d.h. sie gehen mit dem Abschalten verloren. Außerdem ist er passiv, d.h. er kann nicht selbstständig Daten verarbeiten. Mittlerweile sind diese typischen Eigenschaften in der Erwartung der Software-Entwickler fest verankert und manifestieren sich daher in deren Produkten. Wir beobachten nun eine Welle von Innovationen im Bereich der Speicher, die diese Annahmen widerlegen. In diesem Sinne sind sie für die komplette Software-Industrie und Informatik “disruptiv”. Beispiele dafür sind UPMEM PIM (“Near Memory Computing” / NMC: der Hauptspeicher wird aktiv) oder NVRAM (nicht flüchtig; spezielle Performance-Charakteristik). Hinzu kommen Techniken wie High-Bandwidth Memory (HBM) und extrem schnelle Netzwerke, die “Memory Disaggregation” oder direkte Speicherzugriffe über Rechnergrenzen (CXL, RDMA) erlauben. Zusammen genommen versprechen diese Innovationen Systeme mit höherer Verarbeitungsleistung, geringem Energieverbrauch, mehr Verlässlichkeit und Kostenreduktionen. Wie man aber all diese Möglichkeiten für künftige Anwendungs- und Systemsoftware bestmöglich nutzt, ist bisher weitgehend unklar – insbesondere, wenn mehrere Technologien kombiniert genutzt werden. Dieses Projekt soll hier Abhilfe schaffen. Nachdem in der ersten Phase Modelle für die neuartigen Hardwarekomponenten, die Topologie des Gesamtsystems und das Verhalten der Software entworfen wurden, sollen diese nun zur Entwicklung von optimierten Betriebsmittelverwaltungsstrategien genutzt werden. Mit ihrer Hilfe sollen Flaschenhälse, Unterauslastungen und Interferenzen zwischen Anwendungen in komplexen Systemen vermieden werden. Dazu erfolgt die Partitionierung der vorhandenen Betriebsmittel und die Platzierung der anwendungsspezifischen Kontrollflüsse und Daten konsequent auf Basis von Modellen. Ebenso sollen die Modelle durch Entwicklung geeigneter Kalibrierungsverfahren und durch Transferlernen leicht an Hardware- und Softwareänderungen angepasst werden können, um zeitaufwendige Datenerhebungskampagnen zu vermeiden.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive HauptspeichertechnologienMitverantwortlich(e)Dr. Birte  Friesel"
    },
    {
      "project_id": "501993201",
      "url": "https://gepris.dfg.de/gepris/projekt/501993201",
      "title": "Stromausfallbewusster byteadressierbarer virtueller nichtflüchtiger Speicher (PAVE)",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der Wirtschaftsinformatik",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 501993201",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Subsysteme für virtuellen Speicher (VM) lassen die Unterschiede zwischen Sekundär- und Hauptspeicher verschwimmen, so dass auf flüchtige und nicht-flüchtige Daten gleichermaßen mit denselben CPU-Instruktionen zugegriffen werden kann.Jedes VM-Subsystem versucht, häufig benötigte Daten in schnellem, flüchtigen Hauptspeicher zu halten, um die hohe Zugriffslatenz des Sekundärspeichers zu vermeiden, unabhängig davon, ob die Daten selbst flüchtig sind oder nicht. Das Aufkommen von byte-adressierbarem NVRAM ändert dieses Muster nicht grundlegend,da diese Technologie aufgrund der höheren Zugriffslatenz derzeit weder DRAM als schnellen Hauptspeicher,noch herkömmlichen Sekundärspeicher aufgrund der höheren Kosten und geringeren Kapazität,ersetzen kann.Daher sollten VM-Subsysteme NVRAM-gewahr gemacht und so erweitert werden, dass alle verfügbaren byte-adressierbaren Speichertechnologien gemäß ihrer jeweiligen Stärken eingesetzt werden können.Mit Hilfe einer in der virtuellen Speicherverwaltung des Betriebssystemsverankerten Abstraktion lässt sich erreichen, dass bestehende Software ohneweitere Änderung von NVRAM profitieren kann.Dadurch, dass VM-Subsysteme hochkomplexe und fein abgestimmte Softwaresystemesind, die teils seit Jahrzehnten immer weiter entwickelt werden, folgen wireinem minimal-invasivem Ansatz, um NVRAM-Unterstützung in ein bereits existierendes VM-Subsystem zu integrieren, anstatt eines von Grund auf neu zu entwickeln.NVRAM soll als unmittelbarer DRAM-Ersatz bei Speicherknappheit dienen, umProzesse mit großem Speicherbedarf auch bei Ressourcenknappheit lauffähig zu halten.Jedoch müssen aufgrund der höheren NVRAM-Zugriffslatenz auch nicht-flüchtige Daten zeitweise im schnellen, aber flüchtigen DRAM oder in Prozessorcaches bewahrt werden.Unser neues VM-Subsystem - wir passen FreeBSD entsprechend an - ermöglichtdeshalb die Wanderung von Seiten zwischen DRAM und NVRAM, sofern es die verfügbaren Ressourcen erlauben.Somit wird DRAM gewissermaßen als ein großer, durch Software verwalteter, flüchtiger Cache für NVRAM genutzt.Daraus ergibt sich in der Folge das Problem von möglichem Datenverlust im Falle eines Stromausfalls.Das VM-Subsystem muss daher seine eigenen Metadaten in einem konsistenten undwiederherstellbaren Zustand halten und in einem solchen Fall modifizierteSeiten aus dem DRAM im NVRAM persistieren, um Datenverluste zu vermeiden.Ersteres erfordert einen hochgradig effizienten transaktionalen Mechanismus zur Veränderungen von komplexen und parallel genutzen Datenstrukturen, die für die VM-Metadaten zum Einsatz kommen.Letzteres hingegen bedeutet, dass unter Umständen große Mengen an modifizierten Seiten mit einem eng begrenzten Restenergie- und Zeitfenster gesichert werden müssen.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive Hauptspeichertechnologien"
    },
    {
      "project_id": "502444078",
      "url": "https://gepris.dfg.de/gepris/projekt/502444078",
      "title": "VAMPIR – Virtualisierte nicht-funktionale Speichereigenschaften für Daten-Pipeline-Einplanung",
      "subject_area": "Datenmanagement, datenintensive Systeme, Informatik-Methoden in der WirtschaftsinformatikSicherheit und Verlässlichkeit, Betriebs-, Kommunikations- und verteilte Systeme",
      "funding_period": "Förderung seit 2022",
      "project_identifier": "Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 502444078",
      "dfg_procedure": "Schwerpunktprogramme",
      "parent_program": "SPP 2377: \nDisruptive Hauptspeichertechnologien",
      "description": "Aktuelle Fortschritte in Rechnerarchitektur und moderner Hardware stellen einen Wendepunkt für HW/SW-Codesign dar. Obwohl alle Hardwarebereiche von dieser Entwicklung betroffen sind, hat sich vor allem im Bereich Speicher ein beispielloser Wandel vollzogen: Neuartige Hardware verwischt das traditionelle Bild einer Speicherhierarchie. Große Caches, High-Bandwidth-Memory (HBM), Non-Uniform Memory Access (NUMA) oder Remote-Memory-Designs (wie RDMA oder CXL) sowie extrem schnelle SSDs ergänzen das heterogene Portfolio der verfügbaren Speichertechniken. Daher muss die traditionelle Hierarchie durch einen Pool von Speichertechniken ersetzt werden, die in einem mehrdimensionalen Entwurfsraum positioniert sind. Leider macht es dieser Freiheitsgrad Anwendungen (AW) schwer, diese Speicher effizient und effektiv zu nutzen. Im Rahmen unseres geplanten VAMPIR-Projekts untersuchen wir die Forschungshypothese, dass nur ein adäquates HW/SW-Co-Design (genauer: ein innovatives OS/App-Co-Design) in der Lage ist, die individuellen Eigenschaften heterogener Speicher vollständig zu erfassen und auszunutzen. Wir untermauern unsere Hypothese durch Beobachtungen aus zwei Richtungen: Einerseits sehen wir einen klaren Bedarf für ein Betriebssystem (BS), das mehr als nur den Zugriff auf Haupt- und Hintergrundspeicher bietet, sondern eine virtualisierte Speicherschicht mit Funktionen jenseits virtueller Adressräume bereitstellt. Bspw. sollten Komprimierung, Verschlüsselung, Fehlertoleranz, Replikation für ein höheres Maß an Persistenz usw. vom BS bereitgestellt und von AW genutzt werden. Andererseits stellen wir uns vor, dass künftige AW mit einem zugrunde liegenden BS „sprechen“ und die von der AW benötigten individuellen Eigenschaften „aushandeln“. Für diesen Aspekt konzentrieren wir uns auf die Klasse der datenintensiven AW (wie z.B. Datenbank-Query-Engines), die einzelne Datenströme einsetzen, die aus (a) voneinander abhängigen Datenpipelines mit nichtblockierenden Operatoren entlang einer Pipeline und (b) blockierenden Operatoren als Verbindungspunkte zwischen Pipelines bestehen. Im Rahmen des SPP 2377 zielt VAMPIR genau auf das Zusammenspiel der Optimierung der Ausführung datenintensiver AW auf Basis von Datenpipelines im Hinblick auf virtualisierte nicht-funktionale Speichereigenschaften auf disruptiven Speichertechnologien. Die Kernidee von VAMPIR besteht darin, (a) die Fähigkeit eines BS, Speicherzuweisungen unter Berücksichtigung nicht-funktionaler Anforderungen – in Bezug auf Fähigkeiten und auf zeitliche Beschränkungen – bereitzustellen, mit (b) der Möglichkeit der Verarbeitung von Datenpipelines mit einem vordefinierten Zeitplan für Pipeline-Ausführungen und abhängigen Speicheranforderungen zu kombinieren. Wir planen, diese Kombination in beiden Richtungen zu untersuchen, um die Aushandlung von Speicheranforderungen und -bereitstellung zu ermöglichen und damit die Grenzen des Co-Designs von BS und AW zu erweitern.DFG-VerfahrenSchwerpunktprogrammeTeilprojekt zuSPP 2377: \nDisruptive HauptspeichertechnologienMitverantwortlichProfessor Dr.-Ing. Dirk  Habich"
    }
  ]
}